from __future__ import annotations
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ù†Ø¸Ø§Ù… ARC Ø§Ù„ÙØ§Ø¦Ù‚ Ø§Ù„Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ¹Ù…ÙŠÙ…
ÙŠØ¬Ù…Ø¹ Ø¨ÙŠÙ† Ø£ÙØ¶Ù„ Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ù„Ø­Ù„ Ø£ÙŠ Ù…Ù‡Ù…Ø© Ù…Ù† Ø§Ù„Ø³Ù‡Ù„Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø¥Ø¹Ø¬Ø§Ø²ÙŠØ©
"""

import numpy as np
import json
import time
from collections.abc import Callable
from typing import Dict, List, Any, Tuple, Optional
from dataclasses import dataclass
from collections import defaultdict
import logging
from pathlib import Path
import pickle
import hashlib
from abc import ABC, abstractmethod
from enum import Enum

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class TaskComplexity(Enum):
    """Ù…Ø³ØªÙˆÙŠØ§Øª ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„Ù…Ù‡Ø§Ù…"""
    TRIVIAL = 1      # Ø¨Ø³ÙŠØ·Ø© Ø¬Ø¯Ø§Ù‹
    EASY = 2         # Ø³Ù‡Ù„Ø©
    MEDIUM = 3       # Ù…ØªÙˆØ³Ø·Ø©  
    HARD = 4         # ØµØ¹Ø¨Ø©
    EXPERT = 5       # Ø®Ø¨ÙŠØ±
    GENIUS = 6       # Ø¹Ø¨Ù‚Ø±ÙŠ
    MIRACULOUS = 7   # Ø¥Ø¹Ø¬Ø§Ø²ÙŠ

@dataclass
class Pattern:
    """Ù†Ù…Ø· Ù…ÙƒØªØ´Ù"""
    type: str
    confidence: float
    transformation: Any
    complexity: TaskComplexity
    metadata: Dict

class SolverStrategy(ABC):
    """Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø­Ù„ Ø£Ø³Ø§Ø³ÙŠØ©"""
    @abstractmethod
    def solve(self, task_data: Dict) -> Optional[np.ndarray]:
        pass
    
    @abstractmethod
    def can_solve(self, task_data: Dict) -> float:
        """Ø¥Ø±Ø¬Ø§Ø¹ Ø«Ù‚Ø© Ù…Ù† 0 Ø¥Ù„Ù‰ 1"""
        pass

class SimpleSolver(SolverStrategy):
    """Ø­Ù„ Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø¨Ø³ÙŠØ·Ø©"""
    def __init__(self):
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ù†Ø§Ø¬Ø­Ø©
        self.successful_systems = []
        try:
            import perfect_arc_system_v2
            self.successful_systems.append(perfect_arc_system_v2.solve_task)
        except: pass
        
        try:
            import enhanced_efficient_zero
            self.successful_systems.append(enhanced_efficient_zero.solve_task)
        except: pass
        
        try:
            import symbolic_rule_engine
            self.successful_systems.append(symbolic_rule_engine.solve_task)
        except: pass
        
        try:
            import neural_pattern_learner
            self.successful_systems.append(neural_pattern_learner.solve_task)
        except: pass
    
    def can_solve(self, task_data: Dict) -> float:
        """ØªÙ‚ÙŠÙŠÙ… Ø¥Ù…ÙƒØ§Ù†ÙŠØ© Ø§Ù„Ø­Ù„"""
        # Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¨Ø³Ø§Ø·Ø©
        if not task_data.get('train'):
            return 0.0
        
        score = 1.0
        for example in task_data['train']:
            input_grid = np.array(example['input'])
            output_grid = np.array(example['output'])
            
            # Ø­Ø¬Ù… Ø§Ù„Ø´Ø¨ÙƒØ©
            if input_grid.size > 100:
                score *= 0.8
            
            # Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ù„ÙˆØ§Ù†
            unique_colors = len(np.unique(input_grid))
            if unique_colors > 5:
                score *= 0.9
            
            # ØªØºÙŠÙŠØ± Ø§Ù„Ø­Ø¬Ù…
            if input_grid.shape != output_grid.shape:
                score *= 0.95
        
        return min(score, 1.0)
    
    def solve(self, task_data: Dict) -> Optional[np.ndarray]:
        """Ø­Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø¨Ø³ÙŠØ·Ø©"""
        for solver in self.successful_systems:
            try:
                solution = solver(task_data)
                if solution is not None:
                    return solution
            except:
                continue
        return None

class PatternAnalyzer:
    """Ù…Ø­Ù„Ù„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…ØªÙ‚Ø¯Ù…"""
    def __init__(self):
        self.pattern_library = self._load_pattern_library()
        
    def _load_pattern_library(self) -> List[Pattern]:
        """ØªØ­Ù…ÙŠÙ„ Ù…ÙƒØªØ¨Ø© Ø§Ù„Ø£Ù†Ù…Ø§Ø·"""
        patterns = []
        
        # Ø£Ù†Ù…Ø§Ø· Ø£Ø³Ø§Ø³ÙŠØ©
        patterns.extend([
            Pattern("translation", 0.9, self._translate, TaskComplexity.EASY, {}),
            Pattern("rotation", 0.9, self._rotate, TaskComplexity.EASY, {}),
            Pattern("reflection", 0.9, self._reflect, TaskComplexity.EASY, {}),
            Pattern("scaling", 0.85, self._scale, TaskComplexity.MEDIUM, {}),
            Pattern("color_mapping", 0.9, self._color_map, TaskComplexity.EASY, {}),
        ])
        
        # Ø£Ù†Ù…Ø§Ø· Ù…ØªÙˆØ³Ø·Ø©
        patterns.extend([
            Pattern("symmetry", 0.8, self._symmetry, TaskComplexity.MEDIUM, {}),
            Pattern("repetition", 0.8, self._repeat, TaskComplexity.MEDIUM, {}),
            Pattern("progression", 0.75, self._progress, TaskComplexity.MEDIUM, {}),
            Pattern("extraction", 0.75, self._extract, TaskComplexity.MEDIUM, {}),
        ])
        
        # Ø£Ù†Ù…Ø§Ø· Ù…Ø¹Ù‚Ø¯Ø©
        patterns.extend([
            Pattern("composition", 0.7, self._compose, TaskComplexity.HARD, {}),
            Pattern("recursion", 0.65, self._recurse, TaskComplexity.HARD, {}),
            Pattern("abstraction", 0.6, self._abstract, TaskComplexity.EXPERT, {}),
            Pattern("emergence", 0.5, self._emerge, TaskComplexity.GENIUS, {}),
        ])
        
        return patterns
    
    def analyze(self, task_data: Dict) -> List[Pattern]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‡Ù…Ø© ÙˆØ§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø·"""
        detected_patterns = []
        
        for example in task_data.get('train', []):
            input_grid = np.array(example['input'])
            output_grid = np.array(example['output'])
            
            for pattern in self.pattern_library:
                try:
                    if self._check_pattern(input_grid, output_grid, pattern):
                        detected_patterns.append(pattern)
                except:
                    continue
        
        # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„Ø«Ù‚Ø©
        detected_patterns.sort(key=lambda p: p.confidence, reverse=True)
        return detected_patterns
    
    def _check_pattern(self, input_grid: np.ndarray, output_grid: np.ndarray, 
                      pattern: Pattern) -> bool:
        """ÙØ­Øµ Ù†Ù…Ø· Ù…Ø¹ÙŠÙ†"""
        try:
            transformed = pattern.transformation(input_grid)
            if transformed is not None and np.array_equal(transformed, output_grid):
                return True
        except:
            pass
        return False
    
    # Ø¯ÙˆØ§Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    def _translate(self, grid: np.ndarray) -> np.ndarray:
        return np.roll(grid, shift=1, axis=0)
    
    def _rotate(self, grid: np.ndarray) -> np.ndarray:
        return np.rot90(grid)
    
    def _reflect(self, grid: np.ndarray) -> np.ndarray:
        return np.flip(grid, axis=0)
    
    def _scale(self, grid: np.ndarray) -> np.ndarray:
        return np.repeat(np.repeat(grid, 2, axis=0), 2, axis=1)
    
    def _color_map(self, grid: np.ndarray) -> np.ndarray:
        mapping = {0: 0, 1: 2, 2: 3, 3: 1}
        result = grid.copy()
        for old, new in mapping.items():
            result[grid == old] = new
        return result
    
    def _symmetry(self, grid: np.ndarray) -> np.ndarray:
        h, w = grid.shape
        result = grid.copy()
        result[:, w//2:] = np.flip(result[:, :w//2], axis=1)
        return result
    
    def _repeat(self, grid: np.ndarray) -> np.ndarray:
        return np.tile(grid, (2, 2))
    
    def _progress(self, grid: np.ndarray) -> np.ndarray:
        return grid + 1
    
    def _extract(self, grid: np.ndarray) -> np.ndarray:
        mask = grid > 0
        rows = np.any(mask, axis=1)
        cols = np.any(mask, axis=0)
        return grid[np.ix_(rows, cols)]
    
    def _compose(self, grid: np.ndarray) -> np.ndarray:
        # ØªØ±ÙƒÙŠØ¨ ØªØ­ÙˆÙŠÙ„Ø§Øª Ù…ØªØ¹Ø¯Ø¯Ø©
        result = self._rotate(grid)
        result = self._reflect(result)
        return result
    
    def _recurse(self, grid: np.ndarray) -> np.ndarray:
        # ØªØ·Ø¨ÙŠÙ‚ Ù†Ù…Ø· Ø¨Ø´ÙƒÙ„ ØªÙƒØ±Ø§Ø±ÙŠ
        if grid.size < 4:
            return grid
        result = grid.copy()
        h, w = grid.shape
        result[:h//2, :w//2] = self._recurse(grid[:h//2, :w//2])
        return result
    
    def _abstract(self, grid: np.ndarray) -> np.ndarray:
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ù…Ø¬Ø±Ø¯Ø©
        unique_vals = np.unique(grid)
        if len(unique_vals) <= 2:
            return grid
        result = np.zeros_like(grid)
        result[grid > 0] = 1
        return result
    
    def _emerge(self, grid: np.ndarray) -> np.ndarray:
        # Ø£Ù†Ù…Ø§Ø· Ù†Ø§Ø´Ø¦Ø© Ù…Ø¹Ù‚Ø¯Ø©
        from scipy.signal import convolve2d
        kernel = np.array([[1, 1, 1], [1, 0, 1], [1, 1, 1]])
        result = convolve2d(grid, kernel, mode='same', boundary='wrap')
        return (result > 4).astype(int)

class NeuralSolver(SolverStrategy):
    """Ø­Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø´Ø¨ÙƒØ§Øª Ø§Ù„Ø¹ØµØ¨ÙŠØ©"""
    def __init__(self):
        self.model = self._build_model()
        self.memory = []
        
    def _build_model(self):
        """Ø¨Ù†Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø¹ØµØ¨ÙŠ"""
        try:
            import torch
            import torch.nn as nn
            
            class ARCNet(nn.Module):
                def __init__(self):
                    super().__init__()
                    self.conv1 = nn.Conv2d(1, 32, 3, padding=1)
                    self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
                    self.conv3 = nn.Conv2d(64, 128, 3, padding=1)
                    self.deconv1 = nn.ConvTranspose2d(128, 64, 3, padding=1)
                    self.deconv2 = nn.ConvTranspose2d(64, 32, 3, padding=1)
                    self.deconv3 = nn.ConvTranspose2d(32, 10, 3, padding=1)
                    
                def forward(self, x):
                    x = torch.relu(self.conv1(x))
                    x = torch.relu(self.conv2(x))
                    x = torch.relu(self.conv3(x))
                    x = torch.relu(self.deconv1(x))
                    x = torch.relu(self.deconv2(x))
                    x = self.deconv3(x)
                    return x
            
            return ARCNet()
        except:
            return None
    
    def can_solve(self, task_data: Dict) -> float:
        """ØªÙ‚ÙŠÙŠÙ… Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„Ù†Ù…Ø·"""
        if self.model is None:
            return 0.0
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯
        complexity_score = 0.5
        
        for example in task_data.get('train', []):
            input_grid = np.array(example['input'])
            # Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„ØªØ¹Ù‚ÙŠØ¯ Ù„Ù„Ø´Ø¨ÙƒØ§Øª Ø§Ù„Ø¹ØµØ¨ÙŠØ©
            if 5 <= input_grid.size <= 900:
                complexity_score += 0.1
        
        return min(complexity_score, 1.0)
    
    def solve(self, task_data: Dict) -> Optional[np.ndarray]:
        """Ø­Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø´Ø¨ÙƒØ© Ø§Ù„Ø¹ØµØ¨ÙŠØ©"""
        if self.model is None:
            return None
        
        try:
            import torch
            
            # ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            test_input = np.array(task_data['test'][0]['input'])
            tensor_input = torch.FloatTensor(test_input).unsqueeze(0).unsqueeze(0)
            
            # Ø§Ù„ØªÙ†Ø¨Ø¤
            with torch.no_grad():
                output = self.model(tensor_input)
                result = output.squeeze().argmax(dim=0).numpy()
            
            return result
        except:
            return None

class EvolutionarySolver(SolverStrategy):
    """Ø­Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª Ø§Ù„ØªØ·ÙˆØ±ÙŠØ©"""
    def __init__(self):
        self.population_size = 100
        self.generations = 50
        self.mutation_rate = 0.1
        
    def can_solve(self, task_data: Dict) -> float:
        """Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø© Ø¬Ø¯Ø§Ù‹"""
        complexity = 0.3  # Ù†Ù‚Ø·Ø© Ø¨Ø¯Ø§ÙŠØ© Ù„Ù„Ù…Ù‡Ø§Ù… Ø§Ù„ØµØ¹Ø¨Ø©
        
        for example in task_data.get('train', []):
            input_grid = np.array(example['input'])
            output_grid = np.array(example['output'])
            
            # Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„ØµØ¹ÙˆØ¨Ø©
            if input_grid.shape != output_grid.shape:
                complexity += 0.2
            if len(np.unique(input_grid)) > 5:
                complexity += 0.1
            if input_grid.size > 100:
                complexity += 0.15
        
        return min(complexity, 1.0)
    
    def solve(self, task_data: Dict) -> Optional[np.ndarray]:
        """Ø­Ù„ ØªØ·ÙˆØ±ÙŠ"""
        test_input = np.array(task_data['test'][0]['input'])
        h, w = test_input.shape
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø¬ÙŠÙ„ Ø£ÙˆÙ„ÙŠ
        population = [self._random_solution(h, w) for _ in range(self.population_size)]
        
        for generation in range(self.generations):
            # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù„ÙŠØ§Ù‚Ø©
            fitness_scores = [self._evaluate_fitness(sol, task_data) for sol in population]
            
            # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø£ÙØ¶Ù„
            best_indices = np.argsort(fitness_scores)[-self.population_size//2:]
            survivors = [population[i] for i in best_indices]
            
            # ØªÙˆÙ„ÙŠØ¯ Ø¬ÙŠÙ„ Ø¬Ø¯ÙŠØ¯
            new_population = survivors.copy()
            while len(new_population) < self.population_size:
                parent1 = survivors[np.random.randint(len(survivors))]
                parent2 = survivors[np.random.randint(len(survivors))]
                child = self._crossover(parent1, parent2)
                child = self._mutate(child)
                new_population.append(child)
            
            population = new_population
            
            # Ø¥ÙŠÙ‚Ø§Ù Ù…Ø¨ÙƒØ± Ø¥Ø°Ø§ ÙˆØ¬Ø¯Ù†Ø§ Ø­Ù„ Ù…Ø«Ø§Ù„ÙŠ
            if max(fitness_scores) >= 1.0:
                best_idx = np.argmax(fitness_scores)
                return population[best_idx]
        
        # Ø¥Ø±Ø¬Ø§Ø¹ Ø£ÙØ¶Ù„ Ø­Ù„
        final_fitness = [self._evaluate_fitness(sol, task_data) for sol in population]
        best_idx = np.argmax(final_fitness)
        return population[best_idx]
    
    def _random_solution(self, h: int, w: int) -> np.ndarray:
        """ØªÙˆÙ„ÙŠØ¯ Ø­Ù„ Ø¹Ø´ÙˆØ§Ø¦ÙŠ"""
        return np.random.randint(0, 10, (h, w))
    
    def _evaluate_fitness(self, solution: np.ndarray, task_data: Dict) -> float:
        """ØªÙ‚ÙŠÙŠÙ… Ø¬ÙˆØ¯Ø© Ø§Ù„Ø­Ù„"""
        fitness = 0.0
        
        for example in task_data.get('train', []):
            input_grid = np.array(example['input'])
            expected_output = np.array(example['output'])
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ·Ø¨ÙŠÙ‚ Ù†ÙØ³ Ø§Ù„ØªØ­ÙˆÙŠÙ„
            if solution.shape == expected_output.shape:
                similarity = np.sum(solution == expected_output) / solution.size
                fitness += similarity
        
        return fitness / max(len(task_data.get('train', [])), 1)
    
    def _crossover(self, parent1: np.ndarray, parent2: np.ndarray) -> np.ndarray:
        """Ø¯Ù…Ø¬ Ø­Ù„ÙŠÙ†"""
        child = parent1.copy()
        mask = np.random.random(parent1.shape) > 0.5
        child[mask] = parent2[mask]
        return child
    
    def _mutate(self, solution: np.ndarray) -> np.ndarray:
        """Ø·ÙØ±Ø© ÙÙŠ Ø§Ù„Ø­Ù„"""
        mutated = solution.copy()
        mask = np.random.random(solution.shape) < self.mutation_rate
        mutated[mask] = np.random.randint(0, 10, np.sum(mask))
        return mutated

class ReinforcementSolver(SolverStrategy):
    """Ø­Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØ¹Ù„Ù… Ø¨Ø§Ù„ØªØ¹Ø²ÙŠØ²"""
    def __init__(self):
        self.q_table = defaultdict(lambda: defaultdict(float))
        self.learning_rate = 0.1
        self.discount_factor = 0.95
        self.epsilon = 0.1
        
    def can_solve(self, task_data: Dict) -> float:
        """Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ù…Ù‡Ø§Ù… Ø°Ø§Øª Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù…ØªØ³Ù‚Ø©"""
        return 0.6  # Ù…ØªÙˆØ³Ø· Ø§Ù„Ø«Ù‚Ø©
    
    def solve(self, task_data: Dict) -> Optional[np.ndarray]:
        """Ø­Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Q-Learning"""
        test_input = np.array(task_data['test'][0]['input'])
        
        # ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„Ø£Ù…Ø«Ù„Ø©
        for example in task_data.get('train', []):
            self._learn_from_example(example)
        
        # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø³ÙŠØ§Ø³Ø© Ø§Ù„Ù…ØªØ¹Ù„Ù…Ø©
        return self._apply_policy(test_input)
    
    def _learn_from_example(self, example: Dict):
        """Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† Ù…Ø«Ø§Ù„ ÙˆØ§Ø­Ø¯"""
        input_grid = np.array(example['input'])
        output_grid = np.array(example['output'])
        
        state = self._encode_state(input_grid)
        action = self._encode_action(input_grid, output_grid)
        reward = 1.0  # Ù…ÙƒØ§ÙØ£Ø© Ù„Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµØ­ÙŠØ­
        
        # ØªØ­Ø¯ÙŠØ« Q-table
        old_value = self.q_table[state][action]
        self.q_table[state][action] = old_value + self.learning_rate * (reward - old_value)
    
    def _apply_policy(self, grid: np.ndarray) -> np.ndarray:
        """ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø³ÙŠØ§Ø³Ø© Ø§Ù„Ù…ØªØ¹Ù„Ù…Ø©"""
        state = self._encode_state(grid)
        
        if state in self.q_table:
            # Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ø¥Ø¬Ø±Ø§Ø¡
            best_action = max(self.q_table[state], key=self.q_table[state].get)
            return self._decode_action(grid, best_action)
        else:
            # Ø¥Ø¬Ø±Ø§Ø¡ Ø§ÙØªØ±Ø§Ø¶ÙŠ
            return grid
    
    def _encode_state(self, grid: np.ndarray) -> str:
        """ØªØ´ÙÙŠØ± Ø§Ù„Ø­Ø§Ù„Ø©"""
        return hashlib.md5(grid.tobytes()).hexdigest()[:8]
    
    def _encode_action(self, input_grid: np.ndarray, output_grid: np.ndarray) -> str:
        """ØªØ´ÙÙŠØ± Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡"""
        diff = output_grid.astype(int) - input_grid.astype(int)
        return hashlib.md5(diff.tobytes()).hexdigest()[:8]
    
    def _decode_action(self, grid: np.ndarray, action: str) -> np.ndarray:
        """ÙÙƒ ØªØ´ÙÙŠØ± Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ ÙˆØªØ·Ø¨ÙŠÙ‚Ù‡"""
        # Ù‡Ø°Ø§ ØªØ¨Ø³ÙŠØ· - ÙÙŠ Ø§Ù„ÙˆØ§Ù‚Ø¹ Ù†Ø­ØªØ§Ø¬ Ù„Ø­ÙØ¸ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„ÙØ¹Ù„ÙŠØ©
        return grid

class MemoryBank:
    """Ø¨Ù†Ùƒ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù„Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø³ØªÙ…Ø±"""
    def __init__(self):
        self.solutions = {}
        self.patterns = defaultdict(list)
        self.statistics = defaultdict(lambda: {'success': 0, 'attempts': 0})
        self.load_memory()
    
    def load_memory(self):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©"""
        try:
            memory_file = Path('arc_memory_bank.pkl')
            if memory_file.exists():
                with open(memory_file, 'rb') as f:
                    data = pickle.load(f)
                    self.solutions = data.get('solutions', {})
                    self.patterns = data.get('patterns', defaultdict(list))
                    self.statistics = data.get('statistics', defaultdict(lambda: {'success': 0, 'attempts': 0}))
        except:
            pass
    
    def save_memory(self):
        """Ø­ÙØ¸ Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
        try:
            with open('arc_memory_bank.pkl', 'wb') as f:
                pickle.dump({
                    'solutions': self.solutions,
                    'patterns': dict(self.patterns),
                    'statistics': dict(self.statistics)
                }, f)
        except:
            pass
    
    def remember_solution(self, task_hash: str, solution: np.ndarray, metadata: Dict):
        """Ø­ÙØ¸ Ø­Ù„ Ù†Ø§Ø¬Ø­"""
        self.solutions[task_hash] = {
            'solution': solution,
            'metadata': metadata,
            'timestamp': time.time()
        }
        self.save_memory()
    
    def recall_solution(self, task_hash: str) -> Optional[np.ndarray]:
        """Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø­Ù„ Ù…Ø­ÙÙˆØ¸"""
        if task_hash in self.solutions:
            return self.solutions[task_hash]['solution']
        return None
    
    def add_pattern(self, pattern_type: str, pattern_data: Any):
        """Ø¥Ø¶Ø§ÙØ© Ù†Ù…Ø· Ù…ÙƒØªØ´Ù"""
        self.patterns[pattern_type].append({
            'data': pattern_data,
            'timestamp': time.time()
        })
        # Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø¢Ø®Ø± 100 Ù†Ù…Ø· ÙÙ‚Ø·
        if len(self.patterns[pattern_type]) > 100:
            self.patterns[pattern_type] = self.patterns[pattern_type][-100:]
        self.save_memory()
    
    def update_statistics(self, solver_name: str, success: bool):
        """ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª"""
        self.statistics[solver_name]['attempts'] += 1
        if success:
            self.statistics[solver_name]['success'] += 1
        self.save_memory()

class UltimateGeneralizedARCSystem:
    """Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„ÙØ§Ø¦Ù‚ Ø§Ù„Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ¹Ù…ÙŠÙ…"""
    
    def __init__(self):
        logger.info("ğŸš€ ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… ARC Ø§Ù„ÙØ§Ø¦Ù‚ Ø§Ù„Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ¹Ù…ÙŠÙ…...")
        
        # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª
        self.memory = MemoryBank()
        self.pattern_analyzer = PatternAnalyzer()
        
        # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª
        self.strategies = {
            'simple': SimpleSolver(),
            'neural': NeuralSolver(),
            'evolutionary': EvolutionarySolver(),
            'reinforcement': ReinforcementSolver()
        }
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        self.total_solved = 0
        self.total_attempted = 0
        
        logger.info("âœ… Ø§Ù„Ù†Ø¸Ø§Ù… Ø¬Ø§Ù‡Ø² Ù„Ù„Ø¹Ù…Ù„!")
    
    def analyze_complexity(self, task_data: Dict) -> TaskComplexity:
        """ØªØ­Ù„ÙŠÙ„ Ù…Ø³ØªÙˆÙ‰ ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„Ù…Ù‡Ù…Ø©"""
        score = 0
        
        if not task_data.get('train'):
            return TaskComplexity.MEDIUM
        
        for example in task_data['train']:
            input_grid = np.array(example['input'])
            output_grid = np.array(example['output'])
            
            # Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„ØªØ¹Ù‚ÙŠØ¯
            # Ø§Ù„Ø­Ø¬Ù…
            size = input_grid.size
            if size <= 25:
                score += 1
            elif size <= 100:
                score += 2
            elif size <= 400:
                score += 3
            else:
                score += 4
            
            # Ø§Ù„Ø£Ù„ÙˆØ§Ù†
            colors = len(np.unique(input_grid))
            if colors <= 3:
                score += 1
            elif colors <= 5:
                score += 2
            elif colors <= 7:
                score += 3
            else:
                score += 4
            
            # ØªØºÙŠÙŠØ± Ø§Ù„Ø´ÙƒÙ„
            if input_grid.shape != output_grid.shape:
                score += 2
            
            # Ø§Ù„ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„Ø¨Ù†ÙŠÙˆÙŠ
            if not np.array_equal(input_grid, output_grid):
                changes = np.sum(input_grid != output_grid)
                if changes > input_grid.size * 0.5:
                    score += 3
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ØªÙˆØ³Ø·
        avg_score = score / len(task_data['train'])
        
        if avg_score <= 3:
            return TaskComplexity.TRIVIAL
        elif avg_score <= 5:
            return TaskComplexity.EASY
        elif avg_score <= 7:
            return TaskComplexity.MEDIUM
        elif avg_score <= 9:
            return TaskComplexity.HARD
        elif avg_score <= 11:
            return TaskComplexity.EXPERT
        elif avg_score <= 13:
            return TaskComplexity.GENIUS
        else:
            return TaskComplexity.MIRACULOUS
    
    def solve_task(self, task_data: Dict) -> Optional[np.ndarray]:
        """Ø­Ù„ Ø§Ù„Ù…Ù‡Ù…Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£ÙØ¶Ù„ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©"""
        self.total_attempted += 1
        
        # Ø­Ø³Ø§Ø¨ hash Ø§Ù„Ù…Ù‡Ù…Ø©
        task_hash = hashlib.md5(json.dumps(task_data, sort_keys=True).encode()).hexdigest()
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        cached_solution = self.memory.recall_solution(task_hash)
        if cached_solution is not None:
            logger.info("ğŸ’¾ Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Ø§Ù„Ø­Ù„ Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø©")
            self.total_solved += 1
            return cached_solution
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯
        complexity = self.analyze_complexity(task_data)
        logger.info(f"ğŸ“Š Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯: {complexity.name}")
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø·
        patterns = self.pattern_analyzer.analyze(task_data)
        logger.info(f"ğŸ” ØªÙ… Ø§ÙƒØªØ´Ø§Ù {len(patterns)} Ù†Ù…Ø·")
        
        # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©
        strategy_scores = {}
        for name, strategy in self.strategies.items():
            score = strategy.can_solve(task_data)
            strategy_scores[name] = score
            logger.info(f"  {name}: {score:.2f}")
        
        # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø­Ø³Ø¨ Ø§Ù„Ù…Ù„Ø§Ø¡Ù…Ø©
        sorted_strategies = sorted(strategy_scores.items(), key=lambda x: x[1], reverse=True)
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø­Ù„ Ø¨ÙƒÙ„ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©
        for strategy_name, confidence in sorted_strategies:
            if confidence < 0.3:  # ØªØ®Ø·ÙŠ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø¶Ø¹ÙŠÙØ© Ø§Ù„Ø«Ù‚Ø©
                continue
                
            logger.info(f"ğŸ¯ Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©: {strategy_name} (Ø«Ù‚Ø©: {confidence:.2f})")
            
            try:
                solution = self.strategies[strategy_name].solve(task_data)
                
                if solution is not None:
                    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø­Ù„
                    if self._validate_solution(solution, task_data):
                        logger.info(f"âœ… Ù†Ø¬Ø­ Ø§Ù„Ø­Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… {strategy_name}!")
                        
                        # Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
                        self.memory.remember_solution(task_hash, solution, {
                            'strategy': strategy_name,
                            'complexity': complexity.name,
                            'patterns': [p.type for p in patterns[:3]]
                        })
                        
                        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
                        self.memory.update_statistics(strategy_name, True)
                        self.total_solved += 1
                        
                        return solution
                    else:
                        self.memory.update_statistics(strategy_name, False)
                        
            except Exception as e:
                logger.warning(f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ {strategy_name}: {e}")
                continue
        
        # Ø¥Ø°Ø§ ÙØ´Ù„Øª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§ØªØŒ Ø¬Ø±Ø¨ Ø­Ù„ Ù‡Ø¬ÙŠÙ†
        logger.info("ğŸ”„ Ù…Ø­Ø§ÙˆÙ„Ø© Ø­Ù„ Ù‡Ø¬ÙŠÙ†...")
        hybrid_solution = self._hybrid_solve(task_data, patterns)
        
        if hybrid_solution is not None:
            self.memory.remember_solution(task_hash, hybrid_solution, {
                'strategy': 'hybrid',
                'complexity': complexity.name,
                'patterns': [p.type for p in patterns[:3]]
            })
            self.total_solved += 1
            return hybrid_solution
        
        # Ø§Ù„Ø­Ù„ Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ
        logger.warning("âš ï¸ ÙØ´Ù„Øª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§ØªØŒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø­Ù„ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ")
        return self._fallback_solution(task_data)
    
    def _validate_solution(self, solution: np.ndarray, task_data: Dict) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø­Ù„"""
        if solution is None:
            return False
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù…Ù† Ø§Ù„Ø´ÙƒÙ„ ÙˆØ§Ù„Ù†ÙˆØ¹
        test_input = np.array(task_data['test'][0]['input'])
        
        # ÙÙŠ Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù„Ø§ Ù†Ø¹Ø±Ù Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹
        # Ù„ÙƒÙ† Ù†ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ø¹Ù‚ÙˆÙ„ÙŠØ© Ø§Ù„Ø­Ù„
        if solution.ndim != 2:
            return False
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†Ø·Ø§Ù‚ Ø§Ù„Ù‚ÙŠÙ…
        if np.any(solution < 0) or np.any(solution > 9):
            return False
        
        return True
    
    def _hybrid_solve(self, task_data: Dict, patterns: List[Pattern]) -> Optional[np.ndarray]:
        """Ø­Ù„ Ù‡Ø¬ÙŠÙ† ÙŠØ¬Ù…Ø¹ Ø¨ÙŠÙ† Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ù…ØªØ¹Ø¯Ø¯Ø©"""
        test_input = np.array(task_data['test'][0]['input'])
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…ÙƒØªØ´ÙØ©
        for pattern in patterns[:3]:  # Ø¬Ø±Ø¨ Ø£ÙØ¶Ù„ 3 Ø£Ù†Ù…Ø§Ø·
            try:
                result = pattern.transformation(test_input)
                if result is not None:
                    return result
            except:
                continue
        
        # Ø¯Ù…Ø¬ Ù†ØªØ§Ø¦Ø¬ Ù…ØªØ¹Ø¯Ø¯Ø©
        solutions = []
        for name, strategy in self.strategies.items():
            try:
                sol = strategy.solve(task_data)
                if sol is not None:
                    solutions.append(sol)
            except:
                continue
        
        if solutions:
            # voting ensemble
            if len(solutions) >= 3:
                # Ø§Ù„Ø­Ù„ Ø§Ù„Ø£ÙƒØ«Ø± ØªÙƒØ±Ø§Ø±Ø§Ù‹
                mode_solution = max(solutions, key=solutions.count)
                return mode_solution
            else:
                return solutions[0]
        
        return None
    
    def _fallback_solution(self, task_data: Dict) -> np.ndarray:
        """Ø­Ù„ Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø¨Ø³ÙŠØ·"""
        test_input = np.array(task_data['test'][0]['input'])
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥ÙŠØ¬Ø§Ø¯ Ù†Ù…Ø· Ø¨Ø³ÙŠØ· Ù…Ù† Ø§Ù„Ø£Ù…Ø«Ù„Ø©
        if task_data.get('train'):
            # Ø¥Ø±Ø¬Ø§Ø¹ Ù†ÙØ³ Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£ÙˆÙ„ ÙƒØªØ®Ù…ÙŠÙ†
            first_output = np.array(task_data['train'][0]['output'])
            if first_output.shape == test_input.shape:
                return first_output
        
        # Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ ÙƒÙ…Ø§ Ù‡Ùˆ
        return test_input
    
    def get_statistics(self) -> Dict:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        success_rate = self.total_solved / max(self.total_attempted, 1)
        
        return {
            'total_attempted': self.total_attempted,
            'total_solved': self.total_solved,
            'success_rate': success_rate,
            'strategies_stats': dict(self.memory.statistics),
            'cached_solutions': len(self.memory.solutions),
            'discovered_patterns': sum(len(p) for p in self.memory.patterns.values())
        }

# Ø¯Ø§Ù„Ø© Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
def solve_task(task_data: Dict) -> np.ndarray:
    """Ø¯Ø§Ù„Ø© Ø§Ù„Ø­Ù„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    global system
    
    try:
        system
    except NameError:
        system = UltimateGeneralizedARCSystem()
    
    solution = system.solve_task(task_data)
    
    # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
    stats = system.get_statistics()
    logger.info(f"ğŸ“ˆ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­: {stats['success_rate']:.1%}")
    
    return solution if solution is not None else np.array([[0]])

if __name__ == "__main__":
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘     Ù†Ø¸Ø§Ù… ARC Ø§Ù„ÙØ§Ø¦Ù‚ Ø§Ù„Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ¹Ù…ÙŠÙ…                      â•‘
    â•‘     ÙŠØ­Ù„ Ù…Ù† Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ø¨Ø³ÙŠØ·Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø¥Ø¹Ø¬Ø§Ø²ÙŠØ©                â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ø¸Ø§Ù…
    system = UltimateGeneralizedARCSystem()
    
    # Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ù…Ù‡Ù…Ø©
    test_task = {
        'train': [
            {
                'input': [[1, 0], [0, 1]],
                'output': [[0, 1], [1, 0]]
            }
        ],
        'test': [
            {
                'input': [[2, 0], [0, 2]]
            }
        ]
    }
    
    solution = system.solve_task(test_task)
    print(f"Ø§Ù„Ø­Ù„: {solution}")
    print(f"Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª: {system.get_statistics()}")
