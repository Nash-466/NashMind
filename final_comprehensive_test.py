from __future__ import annotations
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø´Ø§Ù…Ù„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù†Ø¸Ø§Ù… NashMind Ø§Ù„Ù…Ø­Ø³Ù†
"""

import json
import numpy as np
import time
from datetime import datetime

def run_final_test():
    """ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø´Ø§Ù…Ù„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ"""
    
    print("ğŸš€ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø´Ø§Ù…Ù„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù†Ø¸Ø§Ù… NashMind")
    print("="*60)
    print(f"ğŸ“… Ø§Ù„ØªØ§Ø±ÙŠØ®: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    with open('arc-agi_training_challenges.json', 'r') as f:
        challenges = json.load(f)
    
    with open('arc-agi_training_solutions.json', 'r') as f:
        solutions = json.load(f)
    
    # Ø§Ø®ØªÙŠØ§Ø± 10 Ù…Ù‡Ø§Ù… Ù…ØªÙ†ÙˆØ¹Ø© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø´Ø§Ù…Ù„
    test_tasks = [
        "007bbfb7",  # Ù…Ù‡Ù…Ø© Ø§Ù„ØªÙˆØ³ÙŠØ¹ Ø§Ù„ØªÙŠ Ø­Ù‚Ù‚Ù†Ø§ ÙÙŠÙ‡Ø§ 100%
        "00d62c1b",  # Ù…Ù‡Ù…Ø© Ø£Ø®Ø±Ù‰
        "025d127b",  # Ù…Ù‡Ù…Ø© Ø«Ø§Ù„Ø«Ø©
        "045e512c",  # Ù…Ù‡Ù…Ø© Ø±Ø§Ø¨Ø¹Ø©
        "0520fde7",  # Ù…Ù‡Ù…Ø© Ø®Ø§Ù…Ø³Ø©
    ]
    
    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù‡Ø§Ù…
    available_tasks = [task for task in test_tasks if task in challenges]
    if len(available_tasks) < len(test_tasks):
        # Ø¥Ø¶Ø§ÙØ© Ù…Ù‡Ø§Ù… Ø¥Ø¶Ø§ÙÙŠØ© Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©
        all_tasks = list(challenges.keys())
        for task in all_tasks:
            if task not in available_tasks and len(available_tasks) < 10:
                available_tasks.append(task)
    
    test_tasks = available_tasks[:10]
    
    print(f"ğŸ“Š Ø§Ø®ØªØ¨Ø§Ø± {len(test_tasks)} Ù…Ù‡Ø§Ù… Ù…ØªÙ†ÙˆØ¹Ø©")
    
    # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
    print("\nğŸ§  ØªÙ‡ÙŠØ¦Ø© NashMind...")
    try:
        from NashMind.aces_system import ACESSystem
        nashmind = ACESSystem()
        print("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© NashMind Ø¨Ù†Ø¬Ø§Ø­")
    except Exception as e:
        print(f"âŒ ÙØ´Ù„ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© NashMind: {e}")
        return
    
    results = []
    start_time = time.time()
    
    for i, task_id in enumerate(test_tasks):
        print(f"\nğŸ¯ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…Ù‡Ù…Ø© {i+1}/{len(test_tasks)}: {task_id}")
        print("-" * 40)
        
        task_data = challenges[task_id]
        correct_solutions = solutions[task_id]
        
        # ØªØ¹Ù„Ù… Ù…Ù† Ø£Ù…Ø«Ù„Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        print(f"ğŸ“š ØªØ¹Ù„Ù… Ù…Ù† {len(task_data['train'])} Ø£Ù…Ø«Ù„Ø© ØªØ¯Ø±ÙŠØ¨...")
        for j, example in enumerate(task_data['train']):
            input_grid = example['input']
            output_grid = example['output']
            
            # ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„Ù…Ø«Ø§Ù„
            nashmind.true_learning_engine.learn_from_experience(
                f"ARC_final_{task_id}_{j}",
                {
                    'input': input_grid,
                    'output': output_grid,
                    'task_id': task_id,
                    'example_type': 'training'
                }
            )
        
        # Ø­Ù„ Ù…Ø«Ø§Ù„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
        test_input = task_data['test'][0]['input']
        correct_output = correct_solutions[0]
        
        input_shape = np.array(test_input).shape
        output_shape = np.array(correct_output).shape
        
        print(f"  ğŸ“‹ Ø§Ù„Ø¯Ø®Ù„: {input_shape}")
        print(f"  ğŸ“‹ Ø§Ù„Ø®Ø±Ø¬ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: {output_shape}")
        
        # Ø­Ù„ Ø§Ù„Ù…Ø³Ø£Ù„Ø©
        task_start = time.time()
        result = nashmind.solve_arc_problem(test_input)
        task_time = time.time() - task_start
        
        if result and 'output' in result:
            predicted_output = result['output']
            strategy = result.get('strategy', 'unknown')
            confidence = result.get('confidence', 0.0)
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©
            accuracy = calculate_accuracy(predicted_output, correct_output)
            
            print(f"  ğŸ¯ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©: {strategy}")
            print(f"  ğŸ¯ Ø§Ù„Ø«Ù‚Ø©: {confidence:.3f}")
            print(f"  ğŸ“Š Ø§Ù„Ø¯Ù‚Ø©: {accuracy:.1f}%")
            print(f"  â±ï¸ Ø§Ù„ÙˆÙ‚Øª: {task_time:.2f} Ø«Ø§Ù†ÙŠØ©")
            
            success = accuracy > 90
            if success:
                print(f"  âœ… Ù†Ø¬Ø­!")
            else:
                print(f"  âŒ ÙØ´Ù„")
            
            results.append({
                'task_id': task_id,
                'strategy': strategy,
                'confidence': confidence,
                'accuracy': accuracy,
                'success': success,
                'time': task_time,
                'input_shape': input_shape,
                'output_shape': output_shape
            })
        else:
            print(f"  âŒ ÙØ´Ù„ ÙÙŠ Ø¥Ù†ØªØ§Ø¬ Ø­Ù„")
            results.append({
                'task_id': task_id,
                'strategy': 'none',
                'confidence': 0.0,
                'accuracy': 0.0,
                'success': False,
                'time': task_time,
                'input_shape': input_shape,
                'output_shape': output_shape
            })
    
    total_time = time.time() - start_time
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
    print("\n" + "="*60)
    print("ğŸ“Š Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù„Ù†ØªØ§Ø¦Ø¬")
    print("="*60)
    
    successful_tasks = [r for r in results if r['success']]
    total_accuracy = sum(r['accuracy'] for r in results) / len(results)
    avg_time = sum(r['time'] for r in results) / len(results)
    
    print(f"âœ… Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù†Ø§Ø¬Ø­Ø©: {len(successful_tasks)}/{len(results)}")
    print(f"ğŸ“ˆ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¯Ù‚Ø©: {total_accuracy:.1f}%")
    print(f"ğŸ¯ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­: {len(successful_tasks)/len(results)*100:.1f}%")
    print(f"â±ï¸ Ù…ØªÙˆØ³Ø· Ø§Ù„ÙˆÙ‚Øª: {avg_time:.2f} Ø«Ø§Ù†ÙŠØ©/Ù…Ù‡Ù…Ø©")
    print(f"â±ï¸ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {total_time:.2f} Ø«Ø§Ù†ÙŠØ©")
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª
    strategy_stats = {}
    for result in results:
        strategy = result['strategy']
        if strategy not in strategy_stats:
            strategy_stats[strategy] = {
                'count': 0, 'success': 0, 'total_accuracy': 0, 'total_time': 0
            }
        
        strategy_stats[strategy]['count'] += 1
        strategy_stats[strategy]['total_accuracy'] += result['accuracy']
        strategy_stats[strategy]['total_time'] += result['time']
        if result['success']:
            strategy_stats[strategy]['success'] += 1
    
    print(f"\nğŸ” Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª:")
    for strategy, stats in strategy_stats.items():
        avg_accuracy = stats['total_accuracy'] / stats['count']
        avg_time = stats['total_time'] / stats['count']
        success_rate = stats['success'] / stats['count'] * 100
        print(f"  {strategy}:")
        print(f"    Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…: {stats['count']} Ù…Ø±Ø©")
        print(f"    Ø§Ù„Ù†Ø¬Ø§Ø­: {success_rate:.0f}%")
        print(f"    Ø§Ù„Ø¯Ù‚Ø©: {avg_accuracy:.1f}%")
        print(f"    Ø§Ù„ÙˆÙ‚Øª: {avg_time:.2f}s")
    
    # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
    final_report = {
        'test_info': {
            'date': datetime.now().isoformat(),
            'total_tasks': len(results),
            'total_time': total_time
        },
        'results': results,
        'summary': {
            'successful_tasks': len(successful_tasks),
            'success_rate': len(successful_tasks)/len(results)*100,
            'average_accuracy': total_accuracy,
            'average_time_per_task': avg_time
        },
        'strategy_stats': strategy_stats
    }
    
    with open('final_comprehensive_test_results.json', 'w', encoding='utf-8') as f:
        json.dump(final_report, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ÙÙŠ: final_comprehensive_test_results.json")
    
    # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¹Ø§Ù…
    print(f"\nğŸ† Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ:")
    if len(successful_tasks)/len(results) >= 0.5:
        print("ğŸŒŸ Ø£Ø¯Ø§Ø¡ Ù…Ù…ØªØ§Ø²! Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠØ­Ù„ Ø£ÙƒØ«Ø± Ù…Ù† 50% Ù…Ù† Ø§Ù„Ù…Ù‡Ø§Ù…")
    elif len(successful_tasks)/len(results) >= 0.3:
        print("ğŸ‘ Ø£Ø¯Ø§Ø¡ Ø¬ÙŠØ¯! Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠØ­Ù„ Ø£ÙƒØ«Ø± Ù…Ù† 30% Ù…Ù† Ø§Ù„Ù…Ù‡Ø§Ù…")
    elif len(successful_tasks)/len(results) >= 0.1:
        print("ğŸ“ˆ Ø£Ø¯Ø§Ø¡ Ù…Ù‚Ø¨ÙˆÙ„! Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠØ­Ù„ Ø£ÙƒØ«Ø± Ù…Ù† 10% Ù…Ù† Ø§Ù„Ù…Ù‡Ø§Ù…")
    else:
        print("ğŸ”§ ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ†! Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠØ­Ù„ Ø£Ù‚Ù„ Ù…Ù† 10% Ù…Ù† Ø§Ù„Ù…Ù‡Ø§Ù…")
    
    return results

def calculate_accuracy(predicted, correct):
    """Ø­Ø³Ø§Ø¨ Ø¯Ù‚Ø© Ø§Ù„Ø­Ù„"""
    try:
        pred_array = np.array(predicted)
        correct_array = np.array(correct)
        
        if pred_array.shape != correct_array.shape:
            return 0.0
        
        matches = np.sum(pred_array == correct_array)
        total = pred_array.size
        
        return (matches / total) * 100
    except:
        return 0.0

if __name__ == "__main__":
    run_final_test()
