from __future__ import annotations
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Ø§Ø®ØªØ¨Ø§Ø± Ø³Ø±ÙŠØ¹ Ù„Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙÙŠ Ù†Ø¸Ø§Ù… NashMind
"""

import json
import numpy as np
from NashMind.aces_system import ACESSystem

def test_new_strategies():
    """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø¹Ù„Ù‰ 5 Ù…Ù‡Ø§Ù…"""
    
    print("ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©")
    print("="*50)
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    with open('arc-agi_training_challenges.json', 'r') as f:
        challenges = json.load(f)
    
    with open('arc-agi_training_solutions.json', 'r') as f:
        solutions = json.load(f)
    
    # Ø§Ø®ØªÙŠØ§Ø± 5 Ù…Ù‡Ø§Ù… Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±
    test_tasks = list(challenges.keys())[:5]
    
    print(f"ğŸ“Š Ø§Ø®ØªØ¨Ø§Ø± {len(test_tasks)} Ù…Ù‡Ø§Ù…")
    
    # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
    print("\nğŸ§  ØªÙ‡ÙŠØ¦Ø© NashMind...")
    nashmind = ACESSystem()
    print("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© NashMind Ø¨Ù†Ø¬Ø§Ø­")
    
    results = []
    
    for i, task_id in enumerate(test_tasks):
        print(f"\nğŸ¯ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…Ù‡Ù…Ø© {i+1}: {task_id}")
        
        task_data = challenges[task_id]
        correct_solutions = solutions[task_id]
        
        # ØªØ¹Ù„Ù… Ù…Ù† Ø£Ù…Ø«Ù„Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        for j, example in enumerate(task_data['train']):
            input_grid = example['input']
            output_grid = example['output']
            
            # ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„Ù…Ø«Ø§Ù„
            nashmind.true_learning_engine.learn_from_experience(
                f"ARC_test_{task_id}_{j}",
                {
                    'input': input_grid,
                    'output': output_grid,
                    'task_id': task_id,
                    'example_type': 'training'
                }
            )
        
        # Ø­Ù„ Ù…Ø«Ø§Ù„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
        test_input = task_data['test'][0]['input']
        correct_output = correct_solutions[0]
        
        print(f"  ğŸ“‹ Ø§Ù„Ø¯Ø®Ù„: {np.array(test_input).shape}")
        print(f"  ğŸ“‹ Ø§Ù„Ø®Ø±Ø¬ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: {np.array(correct_output).shape}")
        
        # Ø­Ù„ Ø§Ù„Ù…Ø³Ø£Ù„Ø©
        result = nashmind.solve_arc_problem(test_input)
        
        if result and 'output' in result:
            predicted_output = result['output']
            strategy = result.get('strategy', 'unknown')
            confidence = result.get('confidence', 0.0)
            
            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©
            accuracy = calculate_accuracy(predicted_output, correct_output)
            
            print(f"  ğŸ¯ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©: {strategy}")
            print(f"  ğŸ¯ Ø§Ù„Ø«Ù‚Ø©: {confidence:.3f}")
            print(f"  ğŸ“Š Ø§Ù„Ø¯Ù‚Ø©: {accuracy:.1f}%")
            
            results.append({
                'task_id': task_id,
                'strategy': strategy,
                'confidence': confidence,
                'accuracy': accuracy,
                'success': accuracy > 90
            })
        else:
            print(f"  âŒ ÙØ´Ù„ ÙÙŠ Ø¥Ù†ØªØ§Ø¬ Ø­Ù„")
            results.append({
                'task_id': task_id,
                'strategy': 'none',
                'confidence': 0.0,
                'accuracy': 0.0,
                'success': False
            })
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    print("\nğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬:")
    print("="*50)
    
    successful_tasks = [r for r in results if r['success']]
    total_accuracy = sum(r['accuracy'] for r in results) / len(results)
    
    print(f"âœ… Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù†Ø§Ø¬Ø­Ø©: {len(successful_tasks)}/{len(results)}")
    print(f"ğŸ“ˆ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¯Ù‚Ø©: {total_accuracy:.1f}%")
    print(f"ğŸ¯ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­: {len(successful_tasks)/len(results)*100:.1f}%")
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª
    strategy_stats = {}
    for result in results:
        strategy = result['strategy']
        if strategy not in strategy_stats:
            strategy_stats[strategy] = {'count': 0, 'success': 0, 'total_accuracy': 0}
        
        strategy_stats[strategy]['count'] += 1
        strategy_stats[strategy]['total_accuracy'] += result['accuracy']
        if result['success']:
            strategy_stats[strategy]['success'] += 1
    
    print(f"\nğŸ” Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª:")
    for strategy, stats in strategy_stats.items():
        avg_accuracy = stats['total_accuracy'] / stats['count']
        success_rate = stats['success'] / stats['count'] * 100
        print(f"  {strategy}: {stats['count']} Ù…Ø±Ø©ØŒ Ù†Ø¬Ø§Ø­ {success_rate:.0f}%ØŒ Ø¯Ù‚Ø© {avg_accuracy:.1f}%")
    
    # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    with open('new_strategies_test_results.json', 'w', encoding='utf-8') as f:
        json.dump({
            'results': results,
            'summary': {
                'total_tasks': len(results),
                'successful_tasks': len(successful_tasks),
                'success_rate': len(successful_tasks)/len(results)*100,
                'average_accuracy': total_accuracy
            },
            'strategy_stats': strategy_stats
        }, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ: new_strategies_test_results.json")
    
    return results

def calculate_accuracy(predicted, correct):
    """Ø­Ø³Ø§Ø¨ Ø¯Ù‚Ø© Ø§Ù„Ø­Ù„"""
    try:
        pred_array = np.array(predicted)
        correct_array = np.array(correct)
        
        if pred_array.shape != correct_array.shape:
            return 0.0
        
        matches = np.sum(pred_array == correct_array)
        total = pred_array.size
        
        return (matches / total) * 100
    except:
        return 0.0

if __name__ == "__main__":
    test_new_strategies()
