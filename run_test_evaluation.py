from __future__ import annotations
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ¯ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ø¹Ù„Ù‰ Ù…Ù‡Ø§Ù… Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
========================================

Ù‡Ø°Ø§ Ø§Ù„Ø³ÙƒØ±ÙŠÙ¾Øª ÙŠÙ‚ÙˆÙ… Ø¨ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ø¹Ù„Ù‰ Ù…Ù‡Ø§Ù… Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
ÙˆØ¥Ù†ØªØ§Ø¬ Ù…Ù„Ù Ø§Ù„Ø­Ù„ÙˆÙ„ Ø¨Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù„Ù„Ù…Ø³Ø§Ø¨Ù‚Ø©.
"""

import json
import numpy as np
import time
import logging
from collections.abc import Callable
from typing import Dict, List, Any, Tuple
from pathlib import Path

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

try:
    from ultra_advanced_arc_system import solve_arc_problem
    SYSTEM_AVAILABLE = True
    logging.info("âœ… Ultra Advanced ARC System loaded successfully")
except ImportError as e:
    logging.error(f"âŒ Failed to import Ultra Advanced ARC System: {e}")
    SYSTEM_AVAILABLE = False


def load_test_data() -> Dict[str, Any]:
    """ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±"""
    
    test_file = Path("arc-agi_test_challenges.json")
    
    if not test_file.exists():
        raise FileNotFoundError(f"Test challenges file not found: {test_file}")
    
    with open(test_file, 'r') as f:
        test_challenges = json.load(f)
    
    logging.info(f"ğŸ§ª Loaded {len(test_challenges)} test challenges")
    return test_challenges


def solve_test_problems(test_challenges: Dict[str, Any], max_problems: int = None) -> Dict[str, List[List[List[int]]]]:
    """Ø­Ù„ Ù…Ù‡Ø§Ù… Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±"""
    
    if not SYSTEM_AVAILABLE:
        raise RuntimeError("Ultra Advanced ARC System not available")
    
    solutions = {}
    problem_count = 0
    
    for problem_id, challenge_data in test_challenges.items():
        
        if max_problems and problem_count >= max_problems:
            break
        
        problem_count += 1
        
        # Get test cases
        test_cases = challenge_data.get("test", [])
        if not test_cases:
            logging.warning(f"âš ï¸  No test cases for problem {problem_id}")
            continue
        
        problem_solutions = []
        
        logging.info(f"ğŸ§ª Solving problem {problem_count}: {problem_id}")
        
        # Solve each test case
        for test_idx, test_case in enumerate(test_cases):
            try:
                # Convert input to numpy array
                input_grid = np.array(test_case["input"])
                
                # Solve using our system
                start_time = time.time()
                solution = solve_arc_problem(input_grid)
                solve_time = time.time() - start_time
                
                # Convert solution back to list format
                solution_list = solution.solution_grid.tolist()
                problem_solutions.append(solution_list)
                
                logging.info(f"  âœ… Test case {test_idx + 1} solved in {solve_time:.3f}s "
                           f"(confidence: {solution.confidence:.3f})")
                
            except Exception as e:
                logging.error(f"  âŒ Error solving test case {test_idx + 1}: {e}")
                
                # Create a fallback solution (copy input or create empty grid)
                try:
                    fallback_solution = test_case["input"]
                    problem_solutions.append(fallback_solution)
                    logging.info(f"  ğŸ”„ Using fallback solution for test case {test_idx + 1}")
                except:
                    # Last resort: create a 1x1 grid with color 0
                    fallback_solution = [[0]]
                    problem_solutions.append(fallback_solution)
                    logging.info(f"  ğŸ†˜ Using emergency fallback for test case {test_idx + 1}")
        
        solutions[problem_id] = problem_solutions
        
        # Progress update
        if problem_count % 10 == 0:
            logging.info(f"ğŸ“Š Progress: {problem_count} problems processed")
    
    return solutions


def validate_solutions(solutions: Dict[str, List[List[List[int]]]]) -> bool:
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø­Ù„ÙˆÙ„"""
    
    logging.info("ğŸ” Validating solution format...")
    
    for problem_id, problem_solutions in solutions.items():
        
        if not isinstance(problem_solutions, list):
            logging.error(f"âŒ Problem {problem_id}: solutions must be a list")
            return False
        
        for test_idx, solution in enumerate(problem_solutions):
            
            if not isinstance(solution, list):
                logging.error(f"âŒ Problem {problem_id}, test {test_idx}: solution must be a list")
                return False
            
            if not solution:
                logging.error(f"âŒ Problem {problem_id}, test {test_idx}: solution cannot be empty")
                return False
            
            # Check that all rows have the same length
            row_lengths = [len(row) for row in solution]
            if len(set(row_lengths)) > 1:
                logging.error(f"âŒ Problem {problem_id}, test {test_idx}: inconsistent row lengths")
                return False
            
            # Check that all values are integers between 0-9
            for row_idx, row in enumerate(solution):
                for col_idx, value in enumerate(row):
                    if not isinstance(value, int) or not (0 <= value <= 9):
                        logging.error(f"âŒ Problem {problem_id}, test {test_idx}, "
                                    f"position ({row_idx}, {col_idx}): invalid value {value}")
                        return False
    
    logging.info("âœ… All solutions have valid format")
    return True


def save_solutions(solutions: Dict[str, List[List[List[int]]]], filename: str = None) -> str:
    """Ø­ÙØ¸ Ø§Ù„Ø­Ù„ÙˆÙ„ ÙÙŠ Ù…Ù„Ù JSON"""
    
    if filename is None:
        timestamp = int(time.time())
        filename = f"test_solutions_{timestamp}.json"
    
    try:
        with open(filename, 'w') as f:
            json.dump(solutions, f, separators=(',', ':'))
        
        logging.info(f"ğŸ’¾ Solutions saved to: {filename}")
        return filename
    
    except Exception as e:
        logging.error(f"âŒ Failed to save solutions: {e}")
        raise


def generate_submission_report(solutions: Dict[str, List[List[List[int]]]], 
                             test_challenges: Dict[str, Any]) -> Dict[str, Any]:
    """Ø¥Ù†ØªØ§Ø¬ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø­Ù„ÙˆÙ„"""
    
    report = {
        "total_problems": len(test_challenges),
        "solved_problems": len(solutions),
        "total_test_cases": 0,
        "solved_test_cases": 0,
        "solution_statistics": {},
        "problem_details": []
    }
    
    for problem_id, challenge_data in test_challenges.items():
        
        test_cases = challenge_data.get("test", [])
        num_test_cases = len(test_cases)
        report["total_test_cases"] += num_test_cases
        
        if problem_id in solutions:
            num_solutions = len(solutions[problem_id])
            report["solved_test_cases"] += num_solutions
            
            # Analyze solution sizes
            for solution in solutions[problem_id]:
                height = len(solution)
                width = len(solution[0]) if solution else 0
                size_key = f"{height}x{width}"
                
                if size_key not in report["solution_statistics"]:
                    report["solution_statistics"][size_key] = 0
                report["solution_statistics"][size_key] += 1
            
            problem_detail = {
                "problem_id": problem_id,
                "test_cases": num_test_cases,
                "solutions_provided": num_solutions,
                "status": "solved" if num_solutions == num_test_cases else "partial"
            }
        else:
            problem_detail = {
                "problem_id": problem_id,
                "test_cases": num_test_cases,
                "solutions_provided": 0,
                "status": "unsolved"
            }
        
        report["problem_details"].append(problem_detail)
    
    # Calculate success rates
    if report["total_problems"] > 0:
        report["problem_success_rate"] = report["solved_problems"] / report["total_problems"]
    
    if report["total_test_cases"] > 0:
        report["test_case_success_rate"] = report["solved_test_cases"] / report["total_test_cases"]
    
    return report


def print_submission_report(report: Dict[str, Any]):
    """Ø·Ø¨Ø§Ø¹Ø© ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø­Ù„ÙˆÙ„"""
    
    print("\n" + "="*80)
    print("ğŸ¯ ØªÙ‚Ø±ÙŠØ± Ø­Ù„ÙˆÙ„ Ù…Ù‡Ø§Ù… Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±")
    print("="*80)
    
    print(f"ğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ù‡Ø§Ù…: {report['total_problems']}")
    print(f"âœ… Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…Ø­Ù„ÙˆÙ„Ø©: {report['solved_problems']}")
    print(f"ğŸ“ˆ Ù…Ø¹Ø¯Ù„ Ù†Ø¬Ø§Ø­ Ø§Ù„Ù…Ù‡Ø§Ù…: {report.get('problem_success_rate', 0):.1%}")
    print()
    
    print(f"ğŸ§ª Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {report['total_test_cases']}")
    print(f"âœ… Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…Ø­Ù„ÙˆÙ„Ø©: {report['solved_test_cases']}")
    print(f"ğŸ“ˆ Ù…Ø¹Ø¯Ù„ Ù†Ø¬Ø§Ø­ Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {report.get('test_case_success_rate', 0):.1%}")
    print()
    
    # Solution size distribution
    if report["solution_statistics"]:
        print("ğŸ“ ØªÙˆØ²ÙŠØ¹ Ø£Ø­Ø¬Ø§Ù… Ø§Ù„Ø­Ù„ÙˆÙ„:")
        for size, count in sorted(report["solution_statistics"].items()):
            print(f"  - {size}: {count} Ø­Ù„")
        print()
    
    # Problem status summary
    status_counts = {}
    for detail in report["problem_details"]:
        status = detail["status"]
        status_counts[status] = status_counts.get(status, 0) + 1
    
    print("ğŸ“‹ Ù…Ù„Ø®Øµ Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ù‡Ø§Ù…:")
    for status, count in status_counts.items():
        print(f"  - {status}: {count} Ù…Ù‡Ù…Ø©")
    
    print("\n" + "="*80)


def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    
    print("ğŸ¯ Ø¨Ø¯Ø¡ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ø¸Ø§Ù… Ø¹Ù„Ù‰ Ù…Ù‡Ø§Ù… Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±...")
    print("=" * 60)
    
    try:
        # Load test data
        test_challenges = load_test_data()
        
        # Solve test problems
        print("ğŸ§  Ø­Ù„ Ù…Ù‡Ø§Ù… Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±...")
        start_time = time.time()
        
        # Remove max_problems parameter to solve all problems
        solutions = solve_test_problems(test_challenges, max_problems=10)  # Test on first 10 for demo
        
        solve_time = time.time() - start_time
        
        # Validate solutions
        if not validate_solutions(solutions):
            raise ValueError("Solution validation failed")
        
        # Save solutions
        filename = save_solutions(solutions, "arc_test_solutions.json")
        
        # Generate and print report
        report = generate_submission_report(solutions, test_challenges)
        print_submission_report(report)
        
        # Save report
        report_filename = filename.replace('.json', '_report.json')
        with open(report_filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“„ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø­Ù„ÙˆÙ„ Ù…Ø­ÙÙˆØ¸ ÙÙŠ: {report_filename}")
        print(f"â±ï¸  Ø¥Ø¬Ù…Ø§Ù„ÙŠ ÙˆÙ‚Øª Ø§Ù„Ø­Ù„: {solve_time:.2f} Ø«Ø§Ù†ÙŠØ©")
        print("ğŸ‰ Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø¨Ù†Ø¬Ø§Ø­!")
        
        return filename
        
    except Exception as e:
        logging.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…: {e}")
        raise


if __name__ == "__main__":
    main()
