from __future__ import annotations
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ØªØ­Ù„ÙŠÙ„ Ù…ÙØµÙ„ Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ø®ØªØ¨Ø§Ø± ARC
"""

import json
import numpy as np
from collections import defaultdict

def load_test_results():
    """ØªØ­Ù…ÙŠÙ„ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±"""
    try:
        with open('arc_test_results.json', 'r') as f:
            return json.load(f)
    except FileNotFoundError:
        print("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Ø§Ù„Ù†ØªØ§Ø¦Ø¬. ÙŠØ±Ø¬Ù‰ ØªØ´ØºÙŠÙ„ arc_ultimate_test.py Ø£ÙˆÙ„Ø§Ù‹")
        return None

def analyze_performance_patterns(results):
    """ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø£Ø¯Ø§Ø¡"""
    
    print("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø£Ø¯Ø§Ø¡")
    print("-"*50)
    
    # ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø¨ Ø¹Ø¯Ø¯ Ø£Ù…Ø«Ù„Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    training_performance = defaultdict(lambda: {"ultimate": [], "arc": []})
    
    for task in results["task_details"]:
        train_count = task["train_examples"]
        training_performance[train_count]["ultimate"].append(task["ultimate_ai"]["accuracy"])
        training_performance[train_count]["arc"].append(task["arc_solver"]["accuracy"])
    
    print("ğŸ“Š Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø­Ø³Ø¨ Ø¹Ø¯Ø¯ Ø£Ù…Ø«Ù„Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨:")
    for train_count in sorted(training_performance.keys()):
        ultimate_avg = np.mean(training_performance[train_count]["ultimate"])
        arc_avg = np.mean(training_performance[train_count]["arc"])
        
        print(f"   {train_count} Ø£Ù…Ø«Ù„Ø©: Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ {ultimate_avg:.2%}, ARC {arc_avg:.2%}")
    
    # ØªØ­Ù„ÙŠÙ„ Ø­Ø³Ø¨ Ø­Ø¬Ù… Ø§Ù„Ù…Ù‡Ù…Ø©
    size_performance = defaultdict(lambda: {"ultimate": [], "arc": []})
    
    for task in results["task_details"]:
        size = task["test_shape"][0] * task["test_shape"][1]  # Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø®Ù„Ø§ÙŠØ§
        size_category = "ØµØºÙŠØ±" if size <= 25 else "Ù…ØªÙˆØ³Ø·" if size <= 100 else "ÙƒØ¨ÙŠØ±"
        
        size_performance[size_category]["ultimate"].append(task["ultimate_ai"]["accuracy"])
        size_performance[size_category]["arc"].append(task["arc_solver"]["accuracy"])
    
    print("\nğŸ“ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø­Ø³Ø¨ Ø­Ø¬Ù… Ø§Ù„Ù…Ù‡Ù…Ø©:")
    for size_cat in ["ØµØºÙŠØ±", "Ù…ØªÙˆØ³Ø·", "ÙƒØ¨ÙŠØ±"]:
        if size_cat in size_performance:
            ultimate_avg = np.mean(size_performance[size_cat]["ultimate"])
            arc_avg = np.mean(size_performance[size_cat]["arc"])
            
            print(f"   {size_cat}: Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ {ultimate_avg:.2%}, ARC {arc_avg:.2%}")

def analyze_failure_modes(results):
    """ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„ÙØ´Ù„"""
    
    print("\nğŸš¨ ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„ÙØ´Ù„")
    print("-"*50)
    
    ultimate_failures = []
    arc_failures = []
    
    for task in results["task_details"]:
        if not task["ultimate_ai"]["perfect_match"]:
            ultimate_failures.append({
                "task_id": task["task_id"],
                "accuracy": task["ultimate_ai"]["accuracy"],
                "shape_match": task["ultimate_ai"]["shape_match"],
                "confidence": task["ultimate_ai"]["confidence"]
            })
        
        if not task["arc_solver"]["perfect_match"]:
            arc_failures.append({
                "task_id": task["task_id"],
                "accuracy": task["arc_solver"]["accuracy"],
                "shape_match": task["arc_solver"]["shape_match"],
                "confidence": task["arc_solver"]["confidence"]
            })
    
    print(f"âŒ ÙØ´Ù„ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ÙÙŠ {len(ultimate_failures)} Ù…Ù‡Ø§Ù…:")
    for failure in ultimate_failures:
        shape_status = "âœ… Ø´ÙƒÙ„ ØµØ­ÙŠØ­" if failure["shape_match"] else "âŒ Ø´ÙƒÙ„ Ø®Ø§Ø·Ø¦"
        print(f"   {failure['task_id']}: Ø¯Ù‚Ø© {failure['accuracy']:.2%}, {shape_status}")
    
    print(f"\nâŒ ÙØ´Ù„ Ù†Ø¸Ø§Ù… ARC ÙÙŠ {len(arc_failures)} Ù…Ù‡Ø§Ù…:")
    for failure in arc_failures:
        shape_status = "âœ… Ø´ÙƒÙ„ ØµØ­ÙŠØ­" if failure["shape_match"] else "âŒ Ø´ÙƒÙ„ Ø®Ø§Ø·Ø¦"
        print(f"   {failure['task_id']}: Ø¯Ù‚Ø© {failure['accuracy']:.2%}, {shape_status}")
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø«Ù‚Ø© Ù…Ù‚Ø§Ø¨Ù„ Ø§Ù„Ø¯Ù‚Ø©
    print(f"\nğŸ¯ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø«Ù‚Ø© Ù…Ù‚Ø§Ø¨Ù„ Ø§Ù„Ø¯Ù‚Ø©:")
    
    ultimate_high_conf_low_acc = [
        task for task in results["task_details"]
        if task["ultimate_ai"]["confidence"] > 0.7 and task["ultimate_ai"]["accuracy"] < 0.5
    ]
    
    arc_high_conf_low_acc = [
        task for task in results["task_details"]
        if task["arc_solver"]["confidence"] > 0.7 and task["arc_solver"]["accuracy"] < 0.5
    ]
    
    print(f"   Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ - Ø«Ù‚Ø© Ø¹Ø§Ù„ÙŠØ© ÙˆØ¯Ù‚Ø© Ù…Ù†Ø®ÙØ¶Ø©: {len(ultimate_high_conf_low_acc)} Ù…Ù‡Ø§Ù…")
    print(f"   Ù†Ø¸Ø§Ù… ARC - Ø«Ù‚Ø© Ø¹Ø§Ù„ÙŠØ© ÙˆØ¯Ù‚Ø© Ù…Ù†Ø®ÙØ¶Ø©: {len(arc_high_conf_low_acc)} Ù…Ù‡Ø§Ù…")

def generate_performance_report(results):
    """Ø¥Ù†ØªØ§Ø¬ ØªÙ‚Ø±ÙŠØ± Ø£Ø¯Ø§Ø¡ Ø´Ø§Ù…Ù„"""
    
    print("\nğŸ“‹ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø´Ø§Ù…Ù„")
    print("="*80)
    
    total_tasks = len(results["task_details"])
    
    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
    ultimate_perfect = sum(1 for task in results["task_details"] if task["ultimate_ai"]["perfect_match"])
    ultimate_shape_correct = sum(1 for task in results["task_details"] if task["ultimate_ai"]["shape_match"])
    ultimate_avg_accuracy = np.mean(results["ultimate_ai"])
    ultimate_avg_confidence = np.mean([task["ultimate_ai"]["confidence"] for task in results["task_details"]])
    ultimate_avg_time = np.mean([task["ultimate_ai"]["processing_time"] for task in results["task_details"]])
    
    # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù†Ø¸Ø§Ù… ARC
    arc_perfect = sum(1 for task in results["task_details"] if task["arc_solver"]["perfect_match"])
    arc_shape_correct = sum(1 for task in results["task_details"] if task["arc_solver"]["shape_match"])
    arc_avg_accuracy = np.mean(results["arc_solver"])
    arc_avg_confidence = np.mean([task["arc_solver"]["confidence"] for task in results["task_details"]])
    arc_avg_time = np.mean([task["arc_solver"]["processing_time"] for task in results["task_details"]])
    
    print(f"ğŸ§  Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ:")
    print(f"   âœ… Ø­Ù„ÙˆÙ„ Ù…Ø«Ø§Ù„ÙŠØ©: {ultimate_perfect}/{total_tasks} ({ultimate_perfect/total_tasks:.1%})")
    print(f"   ğŸ“ Ø£Ø´ÙƒØ§Ù„ ØµØ­ÙŠØ­Ø©: {ultimate_shape_correct}/{total_tasks} ({ultimate_shape_correct/total_tasks:.1%})")
    print(f"   ğŸ“ˆ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¯Ù‚Ø©: {ultimate_avg_accuracy:.2%}")
    print(f"   ğŸ¯ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø«Ù‚Ø©: {ultimate_avg_confidence:.2f}")
    print(f"   â±ï¸ Ù…ØªÙˆØ³Ø· Ø§Ù„ÙˆÙ‚Øª: {ultimate_avg_time:.2f} Ø«Ø§Ù†ÙŠØ©")
    
    print(f"\nğŸ¯ Ù†Ø¸Ø§Ù… ARC Ø§Ù„Ù…ØªØ®ØµØµ:")
    print(f"   âœ… Ø­Ù„ÙˆÙ„ Ù…Ø«Ø§Ù„ÙŠØ©: {arc_perfect}/{total_tasks} ({arc_perfect/total_tasks:.1%})")
    print(f"   ğŸ“ Ø£Ø´ÙƒØ§Ù„ ØµØ­ÙŠØ­Ø©: {arc_shape_correct}/{total_tasks} ({arc_shape_correct/total_tasks:.1%})")
    print(f"   ğŸ“ˆ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¯Ù‚Ø©: {arc_avg_accuracy:.2%}")
    print(f"   ğŸ¯ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø«Ù‚Ø©: {arc_avg_confidence:.2f}")
    print(f"   â±ï¸ Ù…ØªÙˆØ³Ø· Ø§Ù„ÙˆÙ‚Øª: {arc_avg_time:.2f} Ø«Ø§Ù†ÙŠØ©")
    
    # Ù…Ù‚Ø§Ø±Ù†Ø© Ù…ÙØµÙ„Ø©
    print(f"\nğŸ† Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…ÙØµÙ„Ø©:")
    
    accuracy_diff = ultimate_avg_accuracy - arc_avg_accuracy
    perfect_diff = ultimate_perfect - arc_perfect
    time_diff = ultimate_avg_time - arc_avg_time
    
    print(f"   ğŸ“ˆ ÙØ±Ù‚ Ø§Ù„Ø¯Ù‚Ø©: {accuracy_diff:+.2%} Ù„ØµØ§Ù„Ø­ {'Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ' if accuracy_diff > 0 else 'Ù†Ø¸Ø§Ù… ARC'}")
    print(f"   âœ… ÙØ±Ù‚ Ø§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ÙŠØ©: {perfect_diff:+d} Ù„ØµØ§Ù„Ø­ {'Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ' if perfect_diff > 0 else 'Ù†Ø¸Ø§Ù… ARC'}")
    print(f"   â±ï¸ ÙØ±Ù‚ Ø§Ù„ÙˆÙ‚Øª: {time_diff:+.2f} Ø«Ø§Ù†ÙŠØ© ({'Ø£Ø¨Ø·Ø£' if time_diff > 0 else 'Ø£Ø³Ø±Ø¹'} Ù„Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ)")
    
    # ØªÙˆØµÙŠØ§Øª Ù„Ù„ØªØ­Ø³ÙŠÙ†
    print(f"\nğŸ’¡ ØªÙˆØµÙŠØ§Øª Ù„Ù„ØªØ­Ø³ÙŠÙ†:")
    
    if ultimate_avg_accuracy < arc_avg_accuracy:
        print("   ğŸ§  Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ† ÙÙŠ:")
        print("      - Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù†Ù…Ø§Ø·")
        print("      - Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙƒØ§Ù†ÙŠØ©")
        print("      - Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø§Ù„Ù‚Ù„ÙŠÙ„Ø©")
    
    if arc_avg_accuracy < ultimate_avg_accuracy:
        print("   ğŸ¯ Ù†Ø¸Ø§Ù… ARC ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ† ÙÙŠ:")
        print("      - Ø§Ù„ØªØ¹Ù…ÙŠÙ… Ø¹Ù„Ù‰ Ù…Ù‡Ø§Ù… Ø¬Ø¯ÙŠØ¯Ø©")
        print("      - Ø§Ù„ØªÙƒÙŠÙ Ù…Ø¹ Ø£Ù†Ù…Ø§Ø· Ù…Ø¹Ù‚Ø¯Ø©")
        print("      - Ø§Ù„Ø§Ø³ØªÙØ§Ø¯Ø© Ù…Ù† Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©")
    
    if ultimate_avg_time > arc_avg_time * 2:
        print("   âš¡ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ† ÙÙŠ Ø§Ù„Ø³Ø±Ø¹Ø©")
    
    if arc_avg_time > ultimate_avg_time * 2:
        print("   âš¡ Ù†Ø¸Ø§Ù… ARC ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ† ÙÙŠ Ø§Ù„Ø³Ø±Ø¹Ø©")

def create_visualization(results):
    """Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø³ÙˆÙ… Ø¨ÙŠØ§Ù†ÙŠØ© Ù„Ù„Ù†ØªØ§Ø¦Ø¬"""
    
    try:
        import matplotlib.pyplot as plt
        
        # Ø±Ø³Ù… Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¯Ù‚Ø©
        task_names = [f"Task {i+1}" for i in range(len(results["task_details"]))]
        ultimate_accuracies = [task["ultimate_ai"]["accuracy"] for task in results["task_details"]]
        arc_accuracies = [task["arc_solver"]["accuracy"] for task in results["task_details"]]
        
        plt.figure(figsize=(12, 6))
        
        x = np.arange(len(task_names))
        width = 0.35
        
        plt.bar(x - width/2, ultimate_accuracies, width, label='Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ', alpha=0.8)
        plt.bar(x + width/2, arc_accuracies, width, label='Ù†Ø¸Ø§Ù… ARC', alpha=0.8)
        
        plt.xlabel('Ø§Ù„Ù…Ù‡Ø§Ù…')
        plt.ylabel('Ø§Ù„Ø¯Ù‚Ø©')
        plt.title('Ù…Ù‚Ø§Ø±Ù†Ø© Ø¯Ù‚Ø© Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø¹Ù„Ù‰ Ù…Ù‡Ø§Ù… ARC')
        plt.xticks(x, task_names, rotation=45)
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        
        plt.savefig('arc_performance_comparison.png', dpi=300, bbox_inches='tight')
        print("ğŸ“Š ØªÙ… Ø­ÙØ¸ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ ÙÙŠ arc_performance_comparison.png")
        
    except ImportError:
        print("âš ï¸ matplotlib ØºÙŠØ± Ù…ØªÙˆÙØ±ØŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©")

def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    
    results = load_test_results()
    if not results:
        return
    
    print("ğŸ”¬ ØªØ­Ù„ÙŠÙ„ Ù†ØªØ§Ø¦Ø¬ Ø§Ø®ØªØ¨Ø§Ø± ARC")
    print("="*80)
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡
    analyze_performance_patterns(results)
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙØ´Ù„
    analyze_failure_modes(results)
    
    # ØªÙ‚Ø±ÙŠØ± Ø´Ø§Ù…Ù„
    generate_performance_report(results)
    
    # Ø±Ø³ÙˆÙ… Ø¨ÙŠØ§Ù†ÙŠØ©
    create_visualization(results)
    
    print("\nâœ… Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„!")

if __name__ == "__main__":
    main()
