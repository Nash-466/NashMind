from __future__ import annotations
#!/usr/bin/env python3
"""
Automated Training Loop for ARC Tasks
======================================
ÙŠÙ‚ÙˆÙ… Ù‡Ø°Ø§ Ø§Ù„Ø³ÙƒØ±Ø¨Øª Ø¨Ø­Ù„Ù‚Ø© ØªÙ„Ù‚Ø§Ø¦ÙŠØ© Ù„Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø³ØªÙ…Ø± Ù…Ø¹ Ø§Ù„Ù…Ù†Ø³Ù‚ Ø§Ù„Ø°ÙƒÙŠ
Ø§Ù„Ù‡Ø¯Ù: Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ø¯Ù‚Ø© 100% Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ù…Ù‡Ø§Ù… ARC
"""

import json
import os
import sys
import time
import numpy as np
from datetime import datetime
from pathlib import Path
from collections.abc import Callable
from typing import Dict, List, Tuple, Any, Optional
import logging
from collections import defaultdict
import hashlib
import pickle
import random
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed
import psutil
import gc
import warnings
warnings.filterwarnings('ignore')

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('automated_training.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class ExperienceMemory:
    """Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø®Ø¨Ø±Ø§Øª Ù„Ù„Ù†Ø¸Ø§Ù…"""
    def __init__(self):
        self.successful_patterns = defaultdict(list)
        self.failed_patterns = defaultdict(list)
        self.transformations = defaultdict(list)
        self.task_solutions = {}
        self.pattern_scores = defaultdict(float)
        self.dsl_programs = defaultdict(list)
        
    def add_success(self, task_id: str, pattern: Dict, solution: Any, dsl_program: str = None):
        """Ø¥Ø¶Ø§ÙØ© Ù†Ù…Ø· Ù†Ø§Ø¬Ø­"""
        self.successful_patterns[task_id].append(pattern)
        self.task_solutions[task_id] = solution
        if dsl_program:
            self.dsl_programs[task_id].append(dsl_program)
        # ØªØ­Ø¯ÙŠØ« Ù†Ù‚Ø§Ø· Ø§Ù„Ù†Ù…Ø·
        pattern_key = self._pattern_key(pattern)
        self.pattern_scores[pattern_key] += 1.0
        
    def add_failure(self, task_id: str, pattern: Dict, error: str):
        """Ø¥Ø¶Ø§ÙØ© Ù†Ù…Ø· ÙØ§Ø´Ù„"""
        self.failed_patterns[task_id].append({
            'pattern': pattern,
            'error': error,
            'timestamp': datetime.now()
        })
        # ØªÙ‚Ù„ÙŠÙ„ Ù†Ù‚Ø§Ø· Ø§Ù„Ù†Ù…Ø·
        pattern_key = self._pattern_key(pattern)
        self.pattern_scores[pattern_key] -= 0.5
        
    def _pattern_key(self, pattern: Dict) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙØªØ§Ø­ ÙØ±ÙŠØ¯ Ù„Ù„Ù†Ù…Ø·"""
        return hashlib.md5(str(pattern).encode()).hexdigest()
        
    def get_best_patterns(self, limit: int = 10) -> List[Dict]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ Ø§Ù„Ø£Ù†Ù…Ø§Ø·"""
        sorted_patterns = sorted(
            self.pattern_scores.items(),
            key=lambda x: x[1],
            reverse=True
        )
        return sorted_patterns[:limit]
        
    def save(self, filepath: str):
        """Ø­ÙØ¸ Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
        with open(filepath, 'wb') as f:
            pickle.dump(self.__dict__, f)
            
    def load(self, filepath: str):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
        if os.path.exists(filepath):
            with open(filepath, 'rb') as f:
                self.__dict__.update(pickle.load(f))

class DSLGenerator:
    """Ù…ÙˆÙ„Ø¯ Ø¨Ø±Ø§Ù…Ø¬ DSL Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ"""
    def __init__(self, max_length: int = 3):
        self.max_length = max_length
        self.operations = [
            'rotate_90', 'rotate_180', 'rotate_270',
            'flip_horizontal', 'flip_vertical',
            'transpose', 'inverse_colors',
            'extract_pattern', 'apply_pattern',
            'find_symmetry', 'complete_pattern',
            'color_mapping', 'size_scaling',
            'boundary_detection', 'fill_regions',
            'connect_components', 'separate_objects',
            'mirror_pattern', 'extend_pattern',
            'rule_based_transform', 'statistical_transform'
        ]
        self.successful_programs = defaultdict(list)
        
    def generate_program(self, task_data: Dict, memory: ExperienceMemory) -> str:
        """ØªÙˆÙ„ÙŠØ¯ Ø¨Ø±Ù†Ø§Ù…Ø¬ DSL Ù„Ù„Ù…Ù‡Ù…Ø©"""
        programs = []
        
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¨Ø±Ø§Ù…Ø¬ Ø§Ù„Ù†Ø§Ø¬Ø­Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
        task_hash = self._task_hash(task_data)
        if task_hash in self.successful_programs:
            programs.extend(self.successful_programs[task_hash])
            
        # ØªÙˆÙ„ÙŠØ¯ Ø¨Ø±Ø§Ù…Ø¬ Ø¬Ø¯ÙŠØ¯Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„
        analysis = self._analyze_task(task_data)
        
        # Ø¨Ø±Ø§Ù…Ø¬ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„
        if analysis['has_rotation']:
            programs.append(['detect_rotation', 'apply_rotation'])
        if analysis['has_symmetry']:
            programs.append(['find_symmetry', 'apply_symmetry'])
        if analysis['has_pattern']:
            programs.append(['extract_pattern', 'extend_pattern'])
        if analysis['has_color_mapping']:
            programs.append(['analyze_colors', 'color_mapping'])
            
        # Ø¨Ø±Ø§Ù…Ø¬ Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© Ù…ØªÙ‚Ø¯Ù…Ø©
        for _ in range(5):
            length = random.randint(2, self.max_length)
            program = random.sample(self.operations, length)
            programs.append(program)
            
        return programs
        
    def _analyze_task(self, task_data: Dict) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù‡Ù…Ø© Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø®ØµØ§Ø¦Øµ"""
        analysis = {
            'has_rotation': False,
            'has_symmetry': False,
            'has_pattern': False,
            'has_color_mapping': False,
            'grid_sizes': [],
            'color_counts': []
        }
        
        if 'train' in task_data:
            for example in task_data['train']:
                input_grid = np.array(example['input'])
                output_grid = np.array(example['output'])
                
                # ÙØ­Øµ Ø§Ù„ØªØ¯ÙˆÙŠØ±
                for angle in [90, 180, 270]:
                    if np.array_equal(output_grid, np.rot90(input_grid, k=angle//90)):
                        analysis['has_rotation'] = True
                        
                # ÙØ­Øµ Ø§Ù„ØªÙ†Ø§Ø¸Ø±
                if np.array_equal(output_grid, np.flip(input_grid, axis=0)) or \
                   np.array_equal(output_grid, np.flip(input_grid, axis=1)):
                    analysis['has_symmetry'] = True
                    
                # ÙØ­Øµ Ø§Ù„Ø£Ù†Ù…Ø§Ø·
                if self._has_repeating_pattern(input_grid) or \
                   self._has_repeating_pattern(output_grid):
                    analysis['has_pattern'] = True
                    
                # ÙØ­Øµ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ù„ÙˆØ§Ù†
                input_colors = set(input_grid.flatten())
                output_colors = set(output_grid.flatten())
                if input_colors != output_colors:
                    analysis['has_color_mapping'] = True
                    
        return analysis
        
    def _has_repeating_pattern(self, grid: np.ndarray) -> bool:
        """ÙØ­Øµ ÙˆØ¬ÙˆØ¯ Ù†Ù…Ø· Ù…ØªÙƒØ±Ø±"""
        h, w = grid.shape
        # ÙØ­Øµ Ø§Ù„Ø£Ù†Ù…Ø§Ø· 2x2, 3x3, etc
        for size in [2, 3, 4]:
            if h % size == 0 and w % size == 0:
                pattern = grid[:size, :size]
                is_repeating = True
                for i in range(0, h, size):
                    for j in range(0, w, size):
                        if not np.array_equal(grid[i:i+size, j:j+size], pattern):
                            is_repeating = False
                            break
                    if not is_repeating:
                        break
                if is_repeating:
                    return True
        return False
        
    def _task_hash(self, task_data: Dict) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ hash Ù„Ù„Ù…Ù‡Ù…Ø©"""
        return hashlib.md5(json.dumps(task_data, sort_keys=True).encode()).hexdigest()
        
    def increase_complexity(self):
        """Ø²ÙŠØ§Ø¯Ø© ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„Ø¨Ø±Ø§Ù…Ø¬"""
        self.max_length = min(self.max_length + 1, 10)
        logger.info(f"ØªÙ… Ø²ÙŠØ§Ø¯Ø© Ø·ÙˆÙ„ DSL Ø¥Ù„Ù‰ {self.max_length}")

class SmartOrchestrator:
    """Ø§Ù„Ù…Ù†Ø³Ù‚ Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„Ø£Ù†Ø¸Ù…Ø©"""
    def __init__(self):
        self.systems = []
        self.memory = ExperienceMemory()
        self.dsl_generator = DSLGenerator()
        self.transformation_cache = {}
        self.system_performance = defaultdict(lambda: {'success': 0, 'total': 0})
        self.load_systems()
        
    def load_systems(self):
        """ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ù…ØªØ§Ø­Ø©"""
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØºÙ„Ø§Ù Ø§Ù„Ù…ÙˆØ­Ø¯ Ù„ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù†Ø¸Ù…Ø©
        try:
            import unified_solver_wrapper
            self.systems.append({
                'name': 'unified_solver',
                'solve': unified_solver_wrapper.solve_task,
                'priority': 10.0  # Ø£Ø¹Ù„Ù‰ Ø£ÙˆÙ„ÙˆÙŠØ© Ù„Ø£Ù†Ù‡ ÙŠØ¬Ù…Ø¹ ÙƒÙ„ Ø§Ù„Ø£Ù†Ø¸Ù…Ø©
            })
            logger.info("ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØºÙ„Ø§Ù Ø§Ù„Ù…ÙˆØ­Ø¯ Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù†Ø¸Ù…Ø©")
        except Exception as e:
            logger.warning(f"ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ unified_solver_wrapper: {e}")
            
            # ÙÙŠ Ø­Ø§Ù„Ø© ÙØ´Ù„ Ø§Ù„ØºÙ„Ø§Ù Ø§Ù„Ù…ÙˆØ­Ø¯ØŒ Ø­Ù…Ù‘Ù„ Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„ÙØ±Ø¯ÙŠØ©
            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø³Ù‘Ù†
            try:
                import enhanced_arc_solver
                self.systems.append({
                    'name': 'enhanced_arc_solver',
                    'solve': enhanced_arc_solver.solve_task,
                    'priority': 2.0
                })
                logger.info("ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ø³Ù‘Ù†: enhanced_arc_solver")
            except Exception as e2:
                logger.warning(f"ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ enhanced_arc_solver: {e2}")
            
            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
            try:
                import basic_solver
                self.systems.append({
                    'name': 'basic_solver',
                    'solve': basic_solver.solve_task,
                    'priority': 1.0
                })
                logger.info("ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ: basic_solver")
            except Exception as e3:
                logger.warning(f"ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ basic_solver: {e3}")
        
        system_modules = [
            'orchestrated_meta_solver',
            'ultra_advanced_arc_system_v2',
            'ultimate_arc_system',
            'perfect_arc_system_v2',
            'revolutionary_arc_system',
            'enhanced_efficient_zero',
            'deep_learning_arc_system',
            'genius_arc_manager',
            'advanced_simulation_engine',
            'arc_adaptive_hybrid_system'
        ]
        
        for module_name in system_modules:
            try:
                module = __import__(module_name)
                if hasattr(module, 'solve_task'):
                    self.systems.append({
                        'name': module_name,
                        'solve': module.solve_task,
                        'priority': 1.0
                    })
                    logger.info(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù…: {module_name}")
                elif hasattr(module, 'ARCSolver'):
                    solver = module.ARCSolver()
                    self.systems.append({
                        'name': module_name,
                        'solve': solver.solve,
                        'priority': 1.0
                    })
                    logger.info(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù…: {module_name}")
            except Exception as e:
                logger.warning(f"ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ {module_name}: {e}")
        
        # Ø¥Ø¶Ø§ÙØ© Ù†Ø¸Ø§Ù… Ø§ÙØªØ±Ø§Ø¶ÙŠ Ø¨Ø³ÙŠØ· Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø£ÙŠ Ù†Ø¸Ø§Ù…
        if not self.systems:
            logger.warning("Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø£ÙŠ Ù†Ø¸Ø§Ù…! Ø³ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ø¸Ø§Ù… Ø§ÙØªØ±Ø§Ø¶ÙŠ")
            self.systems.append({
                'name': 'default_solver',
                'solve': self._default_solver,
                'priority': 1.0
            })
    
    def _default_solver(self, task_data):
        """Ø­Ù„ Ø§ÙØªØ±Ø§Ø¶ÙŠ Ø¨Ø³ÙŠØ·"""
        if 'train' in task_data and task_data['train']:
            # Ø¥Ø±Ø¬Ø§Ø¹ Ø£ÙˆÙ„ output ÙƒØ­Ù„ Ø§ÙØªØ±Ø§Ø¶ÙŠ
            return np.array(task_data['train'][0]['output'])
        return np.zeros((3, 3))
                
    def solve_with_orchestration(self, task_data: Dict, task_id: str) -> np.ndarray:
        """Ø­Ù„ Ø§Ù„Ù…Ù‡Ù…Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø°ÙƒÙŠ"""
        best_solution = None
        best_score = 0
        solution_history = []
        
        # ØªÙˆÙ„ÙŠØ¯ Ø¨Ø±Ø§Ù…Ø¬ DSL Ù„Ù„Ù…Ù‡Ù…Ø©
        dsl_programs = self.dsl_generator.generate_program(task_data, self.memory)
        
        # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø­Ø³Ø¨ Ø§Ù„Ø£Ø¯Ø§Ø¡
        sorted_systems = sorted(
            self.systems,
            key=lambda x: self.system_performance[x['name']]['success'] / 
                         max(self.system_performance[x['name']]['total'], 1),
            reverse=True
        )
        
        for idx, system in enumerate(sorted_systems):
            try:
                logger.info(f"Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ù†Ø¸Ø§Ù… {idx+1}/{len(self.systems)}: {system['name']}")
                
                # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù†Ø¸Ø§Ù…
                solution = system['solve'](task_data)
                
                if solution is not None:
                    # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø­Ù„
                    score = self._evaluate_solution(solution, task_data)
                    
                    solution_history.append({
                        'system': system['name'],
                        'solution': solution,
                        'score': score,
                        'transformations': []
                    })
                    
                    if score > best_score:
                        best_score = score
                        best_solution = solution
                        
                    # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø­Ù„ Ù…Ø«Ø§Ù„ÙŠØ§Ù‹ØŒ ØªÙˆÙ‚Ù
                    if score >= 1.0:
                        self._update_performance(system['name'], True)
                        self.memory.add_success(task_id, {'system': system['name']}, solution)
                        logger.info(f"âœ“ Ø­Ù„ Ù…Ø«Ø§Ù„ÙŠ Ù…Ù† {system['name']}")
                        return solution
                        
                    # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø­Ù„ Ø¨Ø§Ù„ØªØ­ÙˆÙ„Ø§Øª
                    improved_solution = self._apply_transformations(
                        solution, task_data, dsl_programs
                    )
                    
                    improved_score = self._evaluate_solution(improved_solution, task_data)
                    
                    if improved_score > best_score:
                        best_score = improved_score
                        best_solution = improved_solution
                        solution_history[-1]['transformations'].append('improved')
                        
                        if improved_score >= 1.0:
                            self._update_performance(system['name'], True)
                            self.memory.add_success(
                                task_id,
                                {'system': system['name'], 'transformed': True},
                                improved_solution
                            )
                            logger.info(f"âœ“ Ø­Ù„ Ù…Ø­Ø³Ù‘Ù† Ù…Ø«Ø§Ù„ÙŠ Ù…Ù† {system['name']}")
                            return improved_solution
                            
            except Exception as e:
                logger.warning(f"Ø®Ø·Ø£ ÙÙŠ {system['name']}: {e}")
                self._update_performance(system['name'], False)
                
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¯Ù…Ø¬ Ø§Ù„Ø­Ù„ÙˆÙ„
        if len(solution_history) > 1:
            ensemble_solution = self._ensemble_solutions(solution_history, task_data)
            ensemble_score = self._evaluate_solution(ensemble_solution, task_data)
            
            if ensemble_score > best_score:
                best_solution = ensemble_solution
                logger.info(f"âœ“ Ø­Ù„ Ù…Ø¯Ù…Ø¬ Ø¨Ù†Ù‚Ø§Ø· {ensemble_score:.2%}")
                
        # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ø­Ù„Ø§Ù‹ Ù…Ø«Ø§Ù„ÙŠØ§Ù‹ØŒ Ø§Ø­ÙØ¸ Ø£ÙØ¶Ù„ Ù…Ø­Ø§ÙˆÙ„Ø©
        if best_solution is not None:
            self.memory.add_failure(
                task_id,
                {'best_score': best_score},
                f"Ø£ÙØ¶Ù„ Ù†Ù‚Ø§Ø·: {best_score:.2%}"
            )
            
        return best_solution if best_solution is not None else np.zeros((1, 1))
        
    def _evaluate_solution(self, solution: np.ndarray, task_data: Dict) -> float:
        """ØªÙ‚ÙŠÙŠÙ… Ø¬ÙˆØ¯Ø© Ø§Ù„Ø­Ù„"""
        if 'test' in task_data and task_data['test']:
            test_output = task_data['test'][0].get('output')
            if test_output is not None:
                test_output = np.array(test_output)
                if solution.shape == test_output.shape:
                    return np.mean(solution == test_output)
                    
        # ØªÙ‚ÙŠÙŠÙ… Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø£Ù…Ø«Ù„Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        scores = []
        if 'train' in task_data:
            for example in task_data['train']:
                output = np.array(example['output'])
                if solution.shape == output.shape:
                    score = np.mean(solution == output)
                    scores.append(score)
                    
        return np.mean(scores) if scores else 0.0
        
    def _apply_transformations(self, solution: np.ndarray, task_data: Dict,
                              dsl_programs: List) -> np.ndarray:
        """ØªØ·Ø¨ÙŠÙ‚ ØªØ­ÙˆÙ„Ø§Øª Ø°ÙƒÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ø­Ù„"""
        best_solution = solution.copy()
        best_score = self._evaluate_solution(solution, task_data)
        
        # Ø§Ù„ØªØ­ÙˆÙ„Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        transformations = [
            lambda x: np.rot90(x, k=1),
            lambda x: np.rot90(x, k=2),
            lambda x: np.rot90(x, k=3),
            lambda x: np.flip(x, axis=0),
            lambda x: np.flip(x, axis=1),
            lambda x: np.transpose(x),
            lambda x: self._inverse_colors(x),
            lambda x: self._apply_symmetry(x),
            lambda x: self._complete_pattern(x)
        ]
        
        for transform in transformations:
            try:
                transformed = transform(solution)
                score = self._evaluate_solution(transformed, task_data)
                if score > best_score:
                    best_score = score
                    best_solution = transformed
            except:
                continue
                
        # ØªØ·Ø¨ÙŠÙ‚ Ø¨Ø±Ø§Ù…Ø¬ DSL
        for program in dsl_programs[:5]:  # Ø£ÙˆÙ„ 5 Ø¨Ø±Ø§Ù…Ø¬ ÙÙ‚Ø·
            try:
                transformed = self._execute_dsl_program(solution, program)
                score = self._evaluate_solution(transformed, task_data)
                if score > best_score:
                    best_score = score
                    best_solution = transformed
            except:
                continue
                
        return best_solution
        
    def _execute_dsl_program(self, grid: np.ndarray, program: List[str]) -> np.ndarray:
        """ØªÙ†ÙÙŠØ° Ø¨Ø±Ù†Ø§Ù…Ø¬ DSL"""
        result = grid.copy()
        
        for operation in program:
            if operation == 'rotate_90':
                result = np.rot90(result, k=1)
            elif operation == 'rotate_180':
                result = np.rot90(result, k=2)
            elif operation == 'rotate_270':
                result = np.rot90(result, k=3)
            elif operation == 'flip_horizontal':
                result = np.flip(result, axis=0)
            elif operation == 'flip_vertical':
                result = np.flip(result, axis=1)
            elif operation == 'transpose':
                result = np.transpose(result)
            elif operation == 'inverse_colors':
                result = self._inverse_colors(result)
            elif operation == 'mirror_pattern':
                result = self._apply_symmetry(result)
            # ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª
            
        return result
        
    def _inverse_colors(self, grid: np.ndarray) -> np.ndarray:
        """Ø¹ÙƒØ³ Ø§Ù„Ø£Ù„ÙˆØ§Ù†"""
        max_val = np.max(grid)
        return max_val - grid
        
    def _apply_symmetry(self, grid: np.ndarray) -> np.ndarray:
        """ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªÙ†Ø§Ø¸Ø±"""
        h, w = grid.shape
        if h == w:
            # Ø¬Ø¹Ù„ Ø§Ù„Ù…ØµÙÙˆÙØ© Ù…ØªÙ†Ø§Ø¸Ø±Ø©
            return (grid + grid.T) // 2
        return grid
        
    def _complete_pattern(self, grid: np.ndarray) -> np.ndarray:
        """Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„Ù†Ù…Ø·"""
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥ÙŠØ¬Ø§Ø¯ ÙˆØ¥ÙƒÙ…Ø§Ù„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù†Ø§Ù‚ØµØ©
        h, w = grid.shape
        completed = grid.copy()
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ù†Ù…Ø§Ø· Ù…ØªÙƒØ±Ø±Ø© ÙˆØ¥ÙƒÙ…Ø§Ù„Ù‡Ø§
        for i in range(h):
            for j in range(w):
                if completed[i, j] == 0:  # Ø®Ù„ÙŠØ© ÙØ§Ø±ØºØ©
                    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ù‚ÙŠÙ…Ø© Ù…Ù† Ø§Ù„Ø¬ÙŠØ±Ø§Ù†
                    neighbors = []
                    for di in [-1, 0, 1]:
                        for dj in [-1, 0, 1]:
                            if di == 0 and dj == 0:
                                continue
                            ni, nj = i + di, j + dj
                            if 0 <= ni < h and 0 <= nj < w and completed[ni, nj] != 0:
                                neighbors.append(completed[ni, nj])
                    if neighbors:
                        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø£ÙƒØ«Ø± ØªÙƒØ±Ø§Ø±Ø§Ù‹
                        from collections import Counter
                        completed[i, j] = Counter(neighbors).most_common(1)[0][0]
                        
        return completed
        
    def _ensemble_solutions(self, solution_history: List[Dict], task_data: Dict) -> np.ndarray:
        """Ø¯Ù…Ø¬ Ø§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø©"""
        if not solution_history:
            return np.zeros((1, 1))
            
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø­Ù„ÙˆÙ„ Ù„Ù‡Ø§ Ù†ÙØ³ Ø§Ù„Ø´ÙƒÙ„
        shapes = [s['solution'].shape for s in solution_history]
        if len(set(shapes)) > 1:
            # Ø§Ø®ØªØ± Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹Ø§Ù‹
            from collections import Counter
            common_shape = Counter(shapes).most_common(1)[0][0]
            valid_solutions = [
                s for s in solution_history
                if s['solution'].shape == common_shape
            ]
        else:
            valid_solutions = solution_history
            
        if not valid_solutions:
            return solution_history[0]['solution']
            
        # Ø§Ù„Ø¯Ù…Ø¬ Ø¨Ø§Ù„ØªØµÙˆÙŠØª
        solutions = [s['solution'] for s in valid_solutions]
        weights = [s['score'] for s in valid_solutions]
        
        # ØªØµÙˆÙŠØª Ù…Ø±Ø¬Ø­
        ensemble = np.zeros_like(solutions[0])
        for sol, weight in zip(solutions, weights):
            ensemble = ensemble + sol * weight
            
        # Ø£Ø®Ø° Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø£ÙƒØ«Ø± Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ©
        ensemble = np.round(ensemble / sum(weights)).astype(int)
        
        return ensemble
        
    def _update_performance(self, system_name: str, success: bool):
        """ØªØ­Ø¯ÙŠØ« Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ø¸Ø§Ù…"""
        self.system_performance[system_name]['total'] += 1
        if success:
            self.system_performance[system_name]['success'] += 1
            
    def save_state(self, filepath: str):
        """Ø­ÙØ¸ Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ù†Ø³Ù‚"""
        state = {
            'memory': self.memory.__dict__,
            'dsl_generator': {
                'max_length': self.dsl_generator.max_length,
                'successful_programs': dict(self.dsl_generator.successful_programs)
            },
            'system_performance': dict(self.system_performance)
        }
        with open(filepath, 'w') as f:
            json.dump(state, f, indent=2, default=str)
            
    def load_state(self, filepath: str):
        """ØªØ­Ù…ÙŠÙ„ Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ù†Ø³Ù‚"""
        if os.path.exists(filepath):
            with open(filepath, 'r') as f:
                state = json.load(f)
            self.memory.__dict__.update(state['memory'])
            self.dsl_generator.max_length = state['dsl_generator']['max_length']
            self.dsl_generator.successful_programs.update(
                state['dsl_generator']['successful_programs']
            )
            self.system_performance.update(state['system_performance'])

class AutomatedTrainingLoop:
    """Ø§Ù„Ø­Ù„Ù‚Ø© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ© Ù„Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªÙ‚ÙŠÙŠÙ…"""
    def __init__(self):
        self.orchestrator = SmartOrchestrator()
        self.training_data = {}
        self.evaluation_data = {}
        self.iteration = 0
        self.results_history = []
        self.target_accuracy = 1.0  # 100%
        self.current_accuracy = 0.0
        self.load_data()
        
    def load_data(self):
        """ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªÙ‚ÙŠÙŠÙ…"""
        logger.info("Ø¨Ø¯Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
        
        # ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        training_path = Path("arc-agi_training_challenges.json")
        if training_path.exists():
            try:
                with open(training_path, 'r') as f:
                    self.training_data = json.load(f)
                logger.info(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(self.training_data)} Ù…Ù‡Ù…Ø© ØªØ¯Ø±ÙŠØ¨")
            except Exception as e:
                logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {e}")
                self.training_data = {}
        else:
            logger.error("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Ø§Ù„ØªØ¯Ø±ÙŠØ¨")
            self.training_data = {}
            
        # ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
        evaluation_path = Path("arc-agi_evaluation_challenges.json")
        if evaluation_path.exists():
            try:
                with open(evaluation_path, 'r') as f:
                    self.evaluation_data = json.load(f)
                logger.info(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(self.evaluation_data)} Ù…Ù‡Ù…Ø© ØªÙ‚ÙŠÙŠÙ…")
            except Exception as e:
                logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„ØªÙ‚ÙŠÙŠÙ…: {e}")
                self.evaluation_data = {}
        else:
            logger.warning("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Ø§Ù„ØªÙ‚ÙŠÙŠÙ…")
            self.evaluation_data = {}
                
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø­Ù„ÙˆÙ„ Ø¥Ù† ÙˆØ¬Ø¯Øª
        solutions_path = Path("arc-agi_evaluation_solutions.json")
        if solutions_path.exists():
            try:
                with open(solutions_path, 'r') as f:
                    self.evaluation_solutions = json.load(f)
                logger.info(f"ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø­Ù„ÙˆÙ„ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…: {len(self.evaluation_solutions)} Ø­Ù„")
            except Exception as e:
                logger.warning(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø­Ù„ÙˆÙ„: {e}")
                self.evaluation_solutions = {}
        else:
            logger.warning("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ù„Ù Ø§Ù„Ø­Ù„ÙˆÙ„")
            self.evaluation_solutions = {}
        
        logger.info(f"Ø§Ù†ØªÙ‡Ù‰ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {len(self.training_data)} ØªØ¯Ø±ÙŠØ¨, {len(self.evaluation_data)} ØªÙ‚ÙŠÙŠÙ…")
            
    def train_iteration(self):
        """Ø¯ÙˆØ±Ø© ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ø­Ø¯Ø©"""
        self.iteration += 1
        logger.info(f"\n{'='*60}")
        logger.info(f"Ø¨Ø¯Ø¡ Ø¯ÙˆØ±Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø±Ù‚Ù… {self.iteration}")
        logger.info(f"Ø·ÙˆÙ„ DSL Ø§Ù„Ø­Ø§Ù„ÙŠ: {self.orchestrator.dsl_generator.max_length}")
        logger.info(f"{'='*60}")
        
        success_count = 0
        total_count = 0
        task_results = []
        
        # Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ù…Ù‡Ø§Ù…
        sample_size = min(100, len(self.training_data))  # Ù†Ø¨Ø¯Ø£ Ø¨Ù€ 100 Ù…Ù‡Ù…Ø©
        if self.iteration > 5:
            sample_size = min(500, len(self.training_data))
        if self.iteration > 10:
            sample_size = len(self.training_data)  # ÙƒÙ„ Ø§Ù„Ù…Ù‡Ø§Ù…
            
        sampled_tasks = random.sample(
            list(self.training_data.items()),
            sample_size
        )
        
        for idx, (task_id, task_data) in enumerate(sampled_tasks, 1):
            logger.info(f"Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù‡Ù…Ø© {idx}/{sample_size}: {task_id}")
            
            try:
                # Ø­Ù„ Ø§Ù„Ù…Ù‡Ù…Ø©
                solution = self.orchestrator.solve_with_orchestration(task_data, task_id)
                
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø­Ù„
                is_correct = self._check_solution(task_data, solution)
                
                if is_correct:
                    success_count += 1
                    logger.info(f"âœ“ Ù†Ø¬Ø­ Ø­Ù„ Ø§Ù„Ù…Ù‡Ù…Ø© {task_id}")
                else:
                    logger.info(f"âœ— ÙØ´Ù„ Ø­Ù„ Ø§Ù„Ù…Ù‡Ù…Ø© {task_id}")
                    
                total_count += 1
                
                task_results.append({
                    'task_id': task_id,
                    'success': is_correct,
                    'solution_shape': solution.shape if solution is not None else None
                })
                
                # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø¯Ù… ÙƒÙ„ 10 Ù…Ù‡Ø§Ù…
                if idx % 10 == 0:
                    self._save_progress(task_results)
                    
            except Exception as e:
                logger.error(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© {task_id}: {e}")
                total_count += 1
                
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©
        training_accuracy = success_count / max(total_count, 1)
        logger.info(f"\nÙ†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ¯Ø±ÙŠØ¨:")
        logger.info(f"  - Ù†Ø¬Ø­: {success_count}/{total_count}")
        logger.info(f"  - Ø§Ù„Ø¯Ù‚Ø©: {training_accuracy:.2%}")
        
        return training_accuracy, task_results
        
    def evaluate(self):
        """ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ØªÙ‚ÙŠÙŠÙ…"""
        logger.info(f"\n{'='*60}")
        logger.info("Ø¨Ø¯Ø¡ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ØªÙ‚ÙŠÙŠÙ…")
        logger.info(f"{'='*60}")
        
        success_count = 0
        total_count = 0
        evaluation_results = []
        
        for idx, (task_id, task_data) in enumerate(self.evaluation_data.items(), 1):
            logger.info(f"ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ù‡Ù…Ø© {idx}/{len(self.evaluation_data)}: {task_id}")
            
            try:
                # Ø­Ù„ Ø§Ù„Ù…Ù‡Ù…Ø©
                solution = self.orchestrator.solve_with_orchestration(task_data, task_id)
                
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø­Ù„ Ù…Ø¹ Ø§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„Ù…Ù‚Ø¯Ù…Ø©
                is_correct = False
                if task_id in self.evaluation_solutions:
                    expected = np.array(self.evaluation_solutions[task_id][0])
                    if solution is not None and solution.shape == expected.shape:
                        is_correct = np.array_equal(solution, expected)
                        
                if is_correct:
                    success_count += 1
                    logger.info(f"âœ“ Ù†Ø¬Ø­ Ø­Ù„ Ø§Ù„Ù…Ù‡Ù…Ø© {task_id}")
                else:
                    logger.info(f"âœ— ÙØ´Ù„ Ø­Ù„ Ø§Ù„Ù…Ù‡Ù…Ø© {task_id}")
                    
                total_count += 1
                
                evaluation_results.append({
                    'task_id': task_id,
                    'success': is_correct,
                    'solution': solution.tolist() if solution is not None else None
                })
                
            except Exception as e:
                logger.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙ‚ÙŠÙŠÙ… {task_id}: {e}")
                total_count += 1
                
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ù‚Ø©
        evaluation_accuracy = success_count / max(total_count, 1)
        logger.info(f"\nÙ†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…:")
        logger.info(f"  - Ù†Ø¬Ø­: {success_count}/{total_count}")
        logger.info(f"  - Ø§Ù„Ø¯Ù‚Ø©: {evaluation_accuracy:.2%}")
        
        self.current_accuracy = evaluation_accuracy
        
        # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        self._save_evaluation_results(evaluation_results, evaluation_accuracy)
        
        return evaluation_accuracy, evaluation_results
        
    def analyze_failures(self, results: List[Dict]):
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙˆØ§Ù„ÙØ´Ù„"""
        failures = [r for r in results if not r.get('success', False)]
        
        if not failures:
            logger.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø®Ø·Ø§Ø¡ Ù„Ù„ØªØ­Ù„ÙŠÙ„!")
            return
            
        logger.info(f"\nØªØ­Ù„ÙŠÙ„ {len(failures)} Ù…Ù‡Ù…Ø© ÙØ§Ø´Ù„Ø©:")
        
        # ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„ÙØ´Ù„
        failure_patterns = defaultdict(int)
        
        for failure in failures:
            task_id = failure['task_id']
            if task_id in self.training_data:
                task_data = self.training_data[task_id]
            elif task_id in self.evaluation_data:
                task_data = self.evaluation_data[task_id]
            else:
                continue
                
            # ØªØ­Ù„ÙŠÙ„ Ø®ØµØ§Ø¦Øµ Ø§Ù„Ù…Ù‡Ù…Ø©
            if 'train' in task_data:
                for example in task_data['train']:
                    input_shape = np.array(example['input']).shape
                    output_shape = np.array(example['output']).shape
                    
                    if input_shape != output_shape:
                        failure_patterns['size_change'] += 1
                    if len(set(np.array(example['input']).flatten())) > 5:
                        failure_patterns['many_colors'] += 1
                    if max(input_shape) > 20:
                        failure_patterns['large_grid'] += 1
                        
        logger.info("Ø£Ù†Ù…Ø§Ø· Ø§Ù„ÙØ´Ù„ Ø§Ù„Ù…ÙƒØªØ´ÙØ©:")
        for pattern, count in failure_patterns.items():
            logger.info(f"  - {pattern}: {count} Ù…Ø±Ø©")
            
    def apply_improvements(self):
        """ØªØ·Ø¨ÙŠÙ‚ ØªØ­Ø³ÙŠÙ†Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„"""
        logger.info("\nØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ©...")
        
        # Ø²ÙŠØ§Ø¯Ø© ØªØ¹Ù‚ÙŠØ¯ DSL
        if self.iteration % 3 == 0:
            self.orchestrator.dsl_generator.increase_complexity()
            
        # ØªØ­Ø¯ÙŠØ« Ø£ÙˆÙ„ÙˆÙŠØ§Øª Ø§Ù„Ø£Ù†Ø¸Ù…Ø©
        total_performance = sum(
            s['success'] / max(s['total'], 1)
            for s in self.orchestrator.system_performance.values()
        )
        
        if total_performance > 0:
            for system in self.orchestrator.systems:
                perf = self.orchestrator.system_performance[system['name']]
                if perf['total'] > 0:
                    system['priority'] = perf['success'] / perf['total']
                    
        # Ø¥Ø¶Ø§ÙØ© ØªØ­ÙˆÙ„Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù†Ø§Ø¬Ø­Ø©
        best_patterns = self.orchestrator.memory.get_best_patterns(5)
        logger.info(f"Ø£ÙØ¶Ù„ {len(best_patterns)} Ø£Ù†Ù…Ø§Ø· ØªÙ… Ø§ÙƒØªØ´Ø§ÙÙ‡Ø§")
        
        # Ø­ÙØ¸ Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ù†Ø³Ù‚
        self.orchestrator.save_state(f"orchestrator_state_iter_{self.iteration}.json")
        
    def _check_solution(self, task_data: Dict, solution: np.ndarray) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø­Ù„"""
        if solution is None:
            return False
            
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ù…Ø«Ù„Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        if 'train' in task_data:
            for example in task_data['train']:
                output = np.array(example['output'])
                if solution.shape == output.shape:
                    # Ù†Ù‚Ø¨Ù„ Ø§Ù„Ø­Ù„ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠØ·Ø§Ø¨Ù‚ Ø£Ø­Ø¯ Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø¨Ù†Ø³Ø¨Ø© Ø¹Ø§Ù„ÙŠØ©
                    similarity = np.mean(solution == output)
                    if similarity > 0.95:  # 95% ØªØ´Ø§Ø¨Ù‡
                        return True
                        
        return False
        
    def _save_progress(self, results: List[Dict]):
        """Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø¯Ù…"""
        progress = {
            'iteration': self.iteration,
            'timestamp': datetime.now().isoformat(),
            'results': results,
            'accuracy': sum(r['success'] for r in results) / len(results) if results else 0
        }
        
        with open(f"training_progress_iter_{self.iteration}.json", 'w') as f:
            json.dump(progress, f, indent=2)
            
    def _save_evaluation_results(self, results: List[Dict], accuracy: float):
        """Ø­ÙØ¸ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…"""
        evaluation_data = {
            'iteration': self.iteration,
            'timestamp': datetime.now().isoformat(),
            'accuracy': accuracy,
            'results': results,
            'dsl_length': self.orchestrator.dsl_generator.max_length,
            'system_performance': dict(self.orchestrator.system_performance)
        }
        
        with open(f"evaluation_results_iter_{self.iteration}.json", 'w') as f:
            json.dump(evaluation_data, f, indent=2)
            
        # Ø¥Ø¶Ø§ÙØ© Ù„Ù„Ø³Ø¬Ù„ Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠ
        self.results_history.append({
            'iteration': self.iteration,
            'accuracy': accuracy,
            'timestamp': datetime.now()
        })
        
    def run_automatic_loop(self, max_iterations: int = 100):
        """ØªØ´ØºÙŠÙ„ Ø§Ù„Ø­Ù„Ù‚Ø© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ© Ø­ØªÙ‰ ØªØ­Ù‚ÙŠÙ‚ Ø§Ù„Ù‡Ø¯Ù"""
        logger.info(f"\n{'='*80}")
        logger.info("Ø¨Ø¯Ø¡ Ø§Ù„Ø­Ù„Ù‚Ø© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ© Ù„Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªÙ‚ÙŠÙŠÙ…")
        logger.info(f"Ø§Ù„Ù‡Ø¯Ù: ØªØ­Ù‚ÙŠÙ‚ Ø¯Ù‚Ø© {self.target_accuracy:.0%}")
        logger.info(f"Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ø¯ÙˆØ±Ø§Øª: {max_iterations}")
        logger.info(f"{'='*80}\n")
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¨ÙŠØ§Ù†Ø§Øª
        if not self.training_data or not self.evaluation_data:
            logger.error("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ù„ØªØ¯Ø±ÙŠØ¨!")
            return
        
        start_time = time.time()
        
        while self.iteration < max_iterations:
            iteration_start = time.time()
            logger.info(f"\nØ¨Ø¯Ø¡ Ø§Ù„Ø¯ÙˆØ±Ø© {self.iteration + 1}...")
            
            # Ø¯ÙˆØ±Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨
            train_accuracy, train_results = self.train_iteration()
            
            # Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
            eval_accuracy, eval_results = self.evaluate()
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
            self.analyze_failures(eval_results)
            
            # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª
            self.apply_improvements()
            
            # Ø·Ø¨Ø§Ø¹Ø© Ù…Ù„Ø®Øµ Ø§Ù„Ø¯ÙˆØ±Ø©
            iteration_time = time.time() - iteration_start
            logger.info(f"\n{'='*60}")
            logger.info(f"Ù…Ù„Ø®Øµ Ø§Ù„Ø¯ÙˆØ±Ø© {self.iteration}:")
            logger.info(f"  - Ø¯Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {train_accuracy:.2%}")
            logger.info(f"  - Ø¯Ù‚Ø© Ø§Ù„ØªÙ‚ÙŠÙŠÙ…: {eval_accuracy:.2%}")
            logger.info(f"  - Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ø³ØªØºØ±Ù‚: {iteration_time:.1f} Ø«Ø§Ù†ÙŠØ©")
            logger.info(f"  - Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ÙˆÙ‚Øª: {(time.time() - start_time)/60:.1f} Ø¯Ù‚ÙŠÙ‚Ø©")
            logger.info(f"{'='*60}\n")
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ­Ù‚ÙŠÙ‚ Ø§Ù„Ù‡Ø¯Ù
            if eval_accuracy >= self.target_accuracy:
                logger.info(f"\nğŸ‰ ØªÙ… ØªØ­Ù‚ÙŠÙ‚ Ø§Ù„Ù‡Ø¯Ù! Ø§Ù„Ø¯Ù‚Ø©: {eval_accuracy:.2%}")
                
                # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±
                if self._check_stability():
                    logger.info("âœ“ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù…Ø³ØªÙ‚Ø± Ø¹Ø¨Ø± Ø¹Ø¯Ø© Ø¯ÙˆØ±Ø§Øª")
                    break
                else:
                    logger.info("âš  Ù†Ø­ØªØ§Ø¬ Ù„Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø¯ÙˆØ±Ø§Øª Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø±")
                    
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
            gc.collect()
            
            # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø´Ø§Ù…Ù„
            self._save_comprehensive_report()
            
        # Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        self._final_report()
        
    def _check_stability(self) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø§Ù„Ø£Ø¯Ø§Ø¡"""
        if len(self.results_history) < 3:
            return False
            
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¢Ø®Ø± 3 Ø¯ÙˆØ±Ø§Øª
        recent_accuracies = [r['accuracy'] for r in self.results_history[-3:]]
        
        # ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† Ø¬Ù…ÙŠØ¹Ù‡Ø§ Ø¹Ø§Ù„ÙŠØ© ÙˆÙ…Ø³ØªÙ‚Ø±Ø©
        return all(acc >= 0.98 for acc in recent_accuracies)
        
    def _save_comprehensive_report(self):
        """Ø­ÙØ¸ ØªÙ‚Ø±ÙŠØ± Ø´Ø§Ù…Ù„"""
        report = {
            'iteration': self.iteration,
            'timestamp': datetime.now().isoformat(),
            'current_accuracy': self.current_accuracy,
            'target_accuracy': self.target_accuracy,
            'dsl_length': self.orchestrator.dsl_generator.max_length,
            'history': [
                {
                    'iteration': r['iteration'],
                    'accuracy': r['accuracy'],
                    'timestamp': r['timestamp'].isoformat()
                }
                for r in self.results_history
            ],
            'system_performance': dict(self.orchestrator.system_performance),
            'memory_stats': {
                'successful_patterns': len(self.orchestrator.memory.successful_patterns),
                'failed_patterns': len(self.orchestrator.memory.failed_patterns),
                'cached_solutions': len(self.orchestrator.memory.task_solutions)
            }
        }
        
        with open('comprehensive_training_report.json', 'w') as f:
            json.dump(report, f, indent=2)
            
    def _final_report(self):
        """Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ"""
        logger.info(f"\n{'='*80}")
        logger.info("Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ")
        logger.info(f"{'='*80}")
        logger.info(f"Ø¹Ø¯Ø¯ Ø§Ù„Ø¯ÙˆØ±Ø§Øª: {self.iteration}")
        logger.info(f"Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©: {self.current_accuracy:.2%}")
        logger.info(f"Ø·ÙˆÙ„ DSL Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ: {self.orchestrator.dsl_generator.max_length}")
        
        if self.results_history:
            best_result = max(self.results_history, key=lambda x: x['accuracy'])
            logger.info(f"Ø£ÙØ¶Ù„ Ø¯Ù‚Ø© Ù…Ø­Ù‚Ù‚Ø©: {best_result['accuracy']:.2%} ÙÙŠ Ø§Ù„Ø¯ÙˆØ±Ø© {best_result['iteration']}")
            
        logger.info("\nØ£Ø¯Ø§Ø¡ Ø§Ù„Ø£Ù†Ø¸Ù…Ø©:")
        for system_name, perf in self.orchestrator.system_performance.items():
            if perf['total'] > 0:
                success_rate = perf['success'] / perf['total']
                logger.info(f"  - {system_name}: {success_rate:.2%} ({perf['success']}/{perf['total']})")
                
        logger.info(f"\nØ¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø°Ø§ÙƒØ±Ø©:")
        logger.info(f"  - Ø£Ù†Ù…Ø§Ø· Ù†Ø§Ø¬Ø­Ø©: {len(self.orchestrator.memory.successful_patterns)}")
        logger.info(f"  - Ø£Ù†Ù…Ø§Ø· ÙØ§Ø´Ù„Ø©: {len(self.orchestrator.memory.failed_patterns)}")
        logger.info(f"  - Ø­Ù„ÙˆÙ„ Ù…Ø­ÙÙˆØ¸Ø©: {len(self.orchestrator.memory.task_solutions)}")
        
        logger.info(f"\n{'='*80}")
        logger.info("Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ")
        logger.info(f"{'='*80}")

def main():
    """Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    print("\n" + "="*80)
    print("Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø§Ù„Ø°ÙƒÙŠ Ù„Ù…Ù‡Ø§Ù… ARC")
    print("="*80 + "\n")
    
    try:
        # Ø¥Ù†Ø´Ø§Ø¡ ÙˆØªØ´ØºÙŠÙ„ Ø§Ù„Ø­Ù„Ù‚Ø© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ©
        logger.info("Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ...")
        training_loop = AutomatedTrainingLoop()
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¨ÙŠØ§Ù†Ø§Øª
        if not training_loop.training_data:
            logger.error("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¯Ø±ÙŠØ¨!")
            return
        
        logger.info(f"Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ {len(training_loop.training_data)} Ù…Ù‡Ù…Ø©")
        
        # ØªØ´ØºÙŠÙ„ Ø§Ù„Ø­Ù„Ù‚Ø© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ©
        training_loop.run_automatic_loop(max_iterations=100)
        
    except KeyboardInterrupt:
        logger.info("\nØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù…Ù† Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…")
    except Exception as e:
        logger.error(f"Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {e}")
        import traceback
        traceback.print_exc()
    
    print("\nâœ… Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ")

if __name__ == "__main__":
    main()
